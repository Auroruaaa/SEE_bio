{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262158a4-5c50-4fbb-8c90-c0428e60001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e40e7e0-fd3d-4af8-abf5-8bfabb5d963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Autoencoder model as a subclass of the TensorFlow Model class\n",
    "\n",
    "class SimpleAutoencoder(Model):\n",
    "\tdef __init__(self,latent_dimensions , data_shape):\n",
    "\t\tsuper(SimpleAutoencoder, self).__init__()\n",
    "\t\tself.latent_dimensions = latent_dimensions\n",
    "\t\tself.data_shape = data_shape\n",
    "\n",
    "\t\t# Encoder architecture using a Sequential model\n",
    "\t\tself.encoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Flatten(),\n",
    "\t\t\tlayers.Dense(latent_dimensions, activation='relu', dtype='float32'),\n",
    "\t\t])\n",
    "\n",
    "\t\t# Decoder architecture using another Sequential model\n",
    "\t\tself.decoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Dense(tf.math.reduce_prod(data_shape), activation='sigmoid', dtype='float32'),\n",
    "\t\t\tlayers.Reshape(data_shape)\n",
    "\t\t])\n",
    "\n",
    "\t# Forward pass method defining the encoding and decoding steps\n",
    "\tdef call(self, input_data):\n",
    "\t\tencoded_data = self.encoder(input_data)\n",
    "\t\tdecoded_data = self.decoder(encoded_data)\n",
    "\t\treturn decoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17fd2814-017d-4563-af9f-66cb9c77764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n",
      "2.2.2\n",
      "1.3.2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7f04b45ee430>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m simple_autoencoder \u001b[38;5;241m=\u001b[39m SimpleAutoencoder(latent_dimensions, input_data_shape)\n\u001b[1;32m     22\u001b[0m simple_autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m---> 24\u001b[0m \u001b[43msimple_autoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[28], line 24\u001b[0m, in \u001b[0;36mSimpleAutoencoder.call\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m     23\u001b[0m \tencoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(input_data)\n\u001b[0;32m---> 24\u001b[0m \tdecoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m decoded_data\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7f04b45ee430>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193), dtype=float32)"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_amyloid.pickle\"\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "\n",
    "# Extracting shape information from the testing dataset\n",
    "input_data_shape = X_test.shape[1:]\n",
    "\n",
    "# Specifying the dimensionality of the latent space\n",
    "latent_dimensions = 64\n",
    "\n",
    "# Creating an instance of the SimpleAutoencoder model\n",
    "simple_autoencoder = SimpleAutoencoder(latent_dimensions, input_data_shape)\n",
    "\n",
    "simple_autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "simple_autoencoder.fit(X_train, y_train,\n",
    "\t\t\t\tepochs=1,\n",
    "\t\t\t\tshuffle=True,\n",
    "\t\t\t\tvalidation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20704c71-4d60-44c0-acab-fc38c3cb5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 10193)\n",
      "(155,)\n",
      "(35, 10193)\n",
      "(35,)\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[1:])\n",
    "print(type(y_train))\n",
    "print(y_train.dtype)\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd336f4-aeef-49b0-a6b0-7791b71d6c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

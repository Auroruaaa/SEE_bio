{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a243977-16bf-4a73-8f79-c8bdd8547c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bf8356d-3852-4506-b539-8d6cfccc5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset_amyloid.pickle\"\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb5a26b9-51b0-495c-9131-ea82a64558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (X_train.shape)\n",
    "# print (X_test.shape)\n",
    "# print(X_train[0])\n",
    "# print(X_train[0:])\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "# print (X_train.shape)\n",
    "# print (X_test.shape)\n",
    "# print(X_train[0])\n",
    "# print(X_train[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04882fb3-21c3-4ab8-a45a-9505ff83cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector(Model):\n",
    "  def __init__(self):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(8, activation=\"relu\")])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(140, activation=\"sigmoid\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = AnomalyDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be0f8f2b-3c30-42b1-9d3f-2bc9235cb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder1(Model):\n",
    "  def __init__(self, latent_dim, shape):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.shape = shape\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(tf.math.reduce_prod(shape).numpy(), activation='sigmoid'),\n",
    "      layers.Reshape(shape)\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "shape = X_test.shape[1:]\n",
    "latent_dim = 64\n",
    "autoencoder = Autoencoder1(latent_dim, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23dc89c7-4db3-4574-93a6-356ce5046aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Autoencoder model\n",
    "class Autoencoder2(nn.Module):\n",
    "   def __init__(self, input_size, encoding_dim):\n",
    "       super(Autoencoder, self).__init__()\n",
    "       self.encoder = nn.Sequential(\n",
    "           nn.Linear(input_size, 16),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(16, encoding_dim),\n",
    "           nn.ReLU()\n",
    "       )\n",
    "       self.decoder = nn.Sequential(\n",
    "           nn.Linear(encoding_dim, 16),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(16, input_size),\n",
    "           nn.Sigmoid()\n",
    "       )\n",
    "\n",
    "   def forward(self, x):\n",
    "       x = self.encoder(x)\n",
    "       x = self.decoder(x)\n",
    "       return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbe708ab-b1f9-45af-bd70-3418e5549524",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ab8f6a8-1c15-4c70-8373-7dde7e8c9871",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setting random seed for reproducibility\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Number of input features\u001b[39;00m\n\u001b[1;32m      5\u001b[0m encoding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Desired number of output dimensions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m Autoencoder(input_size, encoding_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "input_size = X.shape[1]  # Number of input features\n",
    "encoding_dim = 3  # Desired number of output dimensions\n",
    "model = Autoencoder(input_size, encoding_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# Training the autoencoder\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "   # Forward pass\n",
    "   outputs = model(X_tensor)\n",
    "   loss = criterion(outputs, X_tensor)\n",
    "\n",
    "   # Backward pass and optimization\n",
    "   optimizer.zero_grad()\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   # Loss for each epoch\n",
    "   print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Encoding the data using the trained autoencoder\n",
    "encoded_data = model.encoder(X_tensor).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8777c8-1149-4a29-a14d-8d8767357c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d9b9b74-68a3-4fa3-aab9-d6c9eb070fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10193 and 140 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, anomaly_detector_1/sequential_15_1/dense_19_1/Sigmoid)' with input shapes: [?,10193], [?,140].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/losses/losses.py:1286\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1284\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_true, dtype\u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1285\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[0;32m-> 1286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mmean(ops\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 10193 and 140 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, anomaly_detector_1/sequential_15_1/dense_19_1/Sigmoid)' with input shapes: [?,10193], [?,140]."
     ]
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0245051-d090-4de8-97a7-266bd54e2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(X_test).numpy()\n",
    "decoded_data = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96aedff0-0dc9-435a-9fdf-150680768191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 10193)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.00392157 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01568628 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "(35, 64)\n",
      "[  0.       102.464584   0.        86.15958   63.324093   0.\n",
      "   0.        13.621096   0.         0.         0.        95.339806\n",
      " 120.054344  36.172222 154.66162   25.494608 134.28531    0.\n",
      "  71.39205    0.        96.422775  37.20052   44.74671   80.33154\n",
      " 163.20021   84.66713    0.        86.95387   50.4607    82.84745\n",
      "   0.       172.92311   73.42575  145.74951   66.24916   77.07766\n",
      "   0.       102.865      0.        76.10905  131.20297  131.87607\n",
      "   0.       120.00564   48.44669    0.         0.         0.\n",
      "  58.26212    0.        45.592968  39.563477   0.         0.\n",
      " 141.19203    0.       107.20339   73.34845   46.63187   47.44703\n",
      "  48.72006   39.714405   0.        23.981995]\n",
      "[[  0.       102.464584   0.       ...  39.714405   0.        23.981995]\n",
      " [  0.       173.762      7.418693 ...  20.142593   0.        89.76246 ]\n",
      " [ 56.897343 422.43896    9.887195 ...  54.66319    0.       106.375206]\n",
      " ...\n",
      " [  0.        96.87141    0.       ...   9.058452   6.529346   7.675514]\n",
      " [  0.       211.23982    0.       ...   0.        73.92682    0.      ]\n",
      " [  0.       139.65639    0.       ...   0.        42.207558  59.94276 ]]\n",
      "(35, 10193)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test[0])\n",
    "print(X_test[0:])\n",
    "\n",
    "print(encoded_data.shape)\n",
    "print(encoded_data[0])\n",
    "print(encoded_data[0:])\n",
    "\n",
    "print(decoded_data.shape)\n",
    "print(decoded_data[0])\n",
    "print(decoded_data[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4beb43-6c28-42ac-ba73-c6484915b04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

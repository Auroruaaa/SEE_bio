{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920caa4-e2f7-4c98-b4a7-aad028ed98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy\n",
    "import pickle\n",
    "import torch.utils \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65880b60-e6f8-49c1-bb5e-2c0eca6f97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auto_encoder_model (nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_fc=nn.Linear(input_dim,5000)\n",
    "        self.hidden_fc=nn.Linear(5000,4000)\n",
    "        self.hidden_fc2=nn.Linear(4000,3000)\n",
    "        self.hidden_fc9=nn.Linear(3000,2000)\n",
    "        self.hidden_fc10=nn.Linear(2000,1000)\n",
    "        self.hidden_fc11=nn.Linear(1000,500)\n",
    "        self.hidden_fc12=nn.Linear(500,200)\n",
    "        self.hidden_fc13=nn.Linear(200,50)\n",
    "\n",
    "\n",
    "        self.output_fc=nn.Linear(50,output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dropout_mid = nn.Dropout(0.05)\n",
    "        self.dropout_small=nn.Dropout(0.05)\n",
    "\n",
    "    def forward(self,x):\n",
    "       batch_size=x.shape[0]\n",
    "       x = x.view(batch_size, -1)\n",
    "       x1=nn.functional.relu(self.input_fc(x))\n",
    "       x1=self.dropout_mid(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc(x1))\n",
    "       x1=self.dropout_mid(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc2(x1))\n",
    "       x1=self.dropout_mid(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc9(x1))\n",
    "       x1=self.dropout_mid(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc10(x1))\n",
    "       x1=self.dropout_mid(x1)\n",
    "\n",
    "       x1=nn.functional.relu(self.hidden_fc11(x1))\n",
    "       x1=self.dropout_small(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc12(x1))\n",
    "       x1=self.dropout_small(x1)\n",
    "       x1=nn.functional.relu(self.hidden_fc13(x1))\n",
    "       x1=self.dropout_small(x1)\n",
    "       #output=nn.functional.sigmoid(self.output_fc(x1))\n",
    "       output=(self.output_fc(x1))\n",
    "\n",
    "       return output \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class train_dataset(Dataset):\n",
    "    def __init__(self,x_feature,y_label):\n",
    "        self.x=x_feature\n",
    "        self.y=y_label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label=[0,0]\n",
    "        if self.y[index]==1:\n",
    "            label=[1,0]\n",
    "        else:\n",
    "            label=[0,1]\n",
    "        \n",
    "        feature=self.x[index]\n",
    "        feature_tensor=torch.tensor(feature).float()\n",
    "        label_tensor=torch.tensor(label).float()\n",
    "\n",
    "        return feature_tensor,label_tensor\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "  \n",
    "    top_pred = y_pred.argmax(1)\n",
    "    top_y= y.argmax(1)\n",
    "    correct = top_pred.eq(top_y).sum()\n",
    "    #print(top_pred)\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    #print(correct)\n",
    "    return acc\n",
    "\n",
    "def model_train(model,dataloader,optimizer,citerion,device):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.train()\n",
    "\n",
    "    for i,data in enumerate(dataloader):\n",
    "        feature,label=data\n",
    "        feature=feature.to(device)\n",
    "        label=label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred=model(feature)\n",
    "        loss=citerion(y_pred,label)\n",
    "        acc=calculate_accuracy(y_pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "\n",
    "    return epoch_loss/len(dataloader),epoch_acc/len(dataloader)\n",
    "\n",
    "\n",
    "def model_evaluate(model,dataloader,criterion,device):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(dataloader):\n",
    "            feature,label=data\n",
    "            feature=feature.to(device)\n",
    "            label=label.to(device)\n",
    "\n",
    "            y_pred=model(feature)\n",
    "\n",
    "            loss=criterion(y_pred,label)\n",
    "            acc=calculate_accuracy(y_pred,label)\n",
    "\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(dataloader),epoch_acc/len(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61da9485-8b42-4f46-a71e-dbef3589bc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n",
      "2.2.2\n",
      "1.3.2\n",
      "X_train shape: (683, 10193)\n",
      "y_train shape: (683,)\n",
      "X_test shape: (151, 10193)\n",
      "y_test shape: (151,)\n",
      "input dimensions 10193\n",
      "\t E 0 Train Loss: 0.668 | Train Acc: 59.98%\n",
      "\t E 0 Test. Loss: 0.659 |  Test. Acc: 63.84%\n",
      "\t E 1 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 1 Test. Loss: 0.654 |  Test. Acc: 63.84%\n",
      "\t E 2 Train Loss: 0.670 | Train Acc: 61.73%\n",
      "\t E 2 Test. Loss: 0.654 |  Test. Acc: 63.84%\n",
      "\t E 3 Train Loss: 0.667 | Train Acc: 61.93%\n",
      "\t E 3 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 4 Train Loss: 0.669 | Train Acc: 61.60%\n",
      "\t E 4 Test. Loss: 0.650 |  Test. Acc: 65.45%\n",
      "\t E 5 Train Loss: 0.668 | Train Acc: 61.73%\n",
      "\t E 5 Test. Loss: 0.658 |  Test. Acc: 63.84%\n",
      "\t E 6 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 6 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 7 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 7 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 8 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 8 Test. Loss: 0.644 |  Test. Acc: 66.25%\n",
      "\t E 9 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 9 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 10 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 10 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 11 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 11 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 12 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 12 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 13 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 13 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 14 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 14 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 15 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 15 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 16 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 16 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 17 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 17 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 18 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 18 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 19 Train Loss: 0.667 | Train Acc: 61.80%\n",
      "\t E 19 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 20 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 20 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 21 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 21 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 22 Train Loss: 0.668 | Train Acc: 61.73%\n",
      "\t E 22 Test. Loss: 0.650 |  Test. Acc: 65.45%\n",
      "\t E 23 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 23 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 24 Train Loss: 0.668 | Train Acc: 61.80%\n",
      "\t E 24 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 25 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 25 Test. Loss: 0.667 |  Test. Acc: 61.43%\n",
      "\t E 26 Train Loss: 0.667 | Train Acc: 62.06%\n",
      "\t E 26 Test. Loss: 0.659 |  Test. Acc: 63.84%\n",
      "\t E 27 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 27 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 28 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 28 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 29 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 29 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 30 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 30 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 31 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 31 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 32 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 32 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 33 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 33 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 34 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 34 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 35 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 35 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 36 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 36 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 37 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 37 Test. Loss: 0.644 |  Test. Acc: 66.25%\n",
      "\t E 38 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 38 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 39 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 39 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 40 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 40 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 41 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 41 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 42 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 42 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 43 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 43 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 44 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 44 Test. Loss: 0.645 |  Test. Acc: 66.25%\n",
      "\t E 45 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 45 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 46 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 46 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 47 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 47 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 48 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 48 Test. Loss: 0.646 |  Test. Acc: 66.25%\n",
      "\t E 49 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 49 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 50 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 50 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 51 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 51 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 52 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 52 Test. Loss: 0.663 |  Test. Acc: 63.04%\n",
      "\t E 53 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 53 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 54 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 54 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 55 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 55 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 56 Train Loss: 0.667 | Train Acc: 61.80%\n",
      "\t E 56 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 57 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 57 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 58 Train Loss: 0.667 | Train Acc: 61.54%\n",
      "\t E 58 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 59 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 59 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 60 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 60 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 61 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 61 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 62 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 62 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 63 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 63 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 64 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 64 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 65 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 65 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 66 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 66 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 67 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 67 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 68 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 68 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 69 Train Loss: 0.667 | Train Acc: 61.87%\n",
      "\t E 69 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 70 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 70 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 71 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 71 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 72 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 72 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 73 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 73 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 74 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 74 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 75 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 75 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 76 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 76 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 77 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 77 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 78 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 78 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 79 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 79 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 80 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 80 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 81 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 81 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 82 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 82 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 83 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 83 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 84 Train Loss: 0.666 | Train Acc: 61.60%\n",
      "\t E 84 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 85 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 85 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 86 Train Loss: 0.668 | Train Acc: 61.60%\n",
      "\t E 86 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 87 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 87 Test. Loss: 0.650 |  Test. Acc: 64.64%\n",
      "\t E 88 Train Loss: 0.667 | Train Acc: 61.93%\n",
      "\t E 88 Test. Loss: 0.645 |  Test. Acc: 65.45%\n",
      "\t E 89 Train Loss: 0.671 | Train Acc: 61.73%\n",
      "\t E 89 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 90 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 90 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 91 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 91 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 92 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 92 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 93 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 93 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 94 Train Loss: 0.666 | Train Acc: 61.93%\n",
      "\t E 94 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 95 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 95 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 96 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 96 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 97 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 97 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 98 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 98 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 99 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 99 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 100 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 100 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 101 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 101 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 102 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 102 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 103 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 103 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 104 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 104 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 105 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 105 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 106 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 106 Test. Loss: 0.657 |  Test. Acc: 63.84%\n",
      "\t E 107 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 107 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 108 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 108 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 109 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 109 Test. Loss: 0.644 |  Test. Acc: 66.25%\n",
      "\t E 110 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 110 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 111 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 111 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 112 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 112 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 113 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 113 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 114 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 114 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 115 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 115 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 116 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 116 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 117 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 117 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 118 Train Loss: 0.666 | Train Acc: 61.93%\n",
      "\t E 118 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 119 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 119 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 120 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 120 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 121 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 121 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 122 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 122 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 123 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 123 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 124 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 124 Test. Loss: 0.650 |  Test. Acc: 65.45%\n",
      "\t E 125 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 125 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 126 Train Loss: 0.667 | Train Acc: 61.54%\n",
      "\t E 126 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 127 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 127 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 128 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 128 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 129 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 129 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 130 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 130 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 131 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 131 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 132 Train Loss: 0.668 | Train Acc: 61.60%\n",
      "\t E 132 Test. Loss: 0.667 |  Test. Acc: 61.43%\n",
      "\t E 133 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 133 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 134 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 134 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 135 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 135 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 136 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 136 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 137 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 137 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 138 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 138 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 139 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 139 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 140 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 140 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 141 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 141 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 142 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 142 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 143 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 143 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 144 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 144 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 145 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 145 Test. Loss: 0.654 |  Test. Acc: 63.84%\n",
      "\t E 146 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 146 Test. Loss: 0.655 |  Test. Acc: 64.64%\n",
      "\t E 147 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 147 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 148 Train Loss: 0.667 | Train Acc: 61.80%\n",
      "\t E 148 Test. Loss: 0.660 |  Test. Acc: 65.45%\n",
      "\t E 149 Train Loss: 0.668 | Train Acc: 61.80%\n",
      "\t E 149 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 150 Train Loss: 0.668 | Train Acc: 61.73%\n",
      "\t E 150 Test. Loss: 0.665 |  Test. Acc: 63.04%\n",
      "\t E 151 Train Loss: 0.667 | Train Acc: 61.87%\n",
      "\t E 151 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 152 Train Loss: 0.667 | Train Acc: 61.54%\n",
      "\t E 152 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 153 Train Loss: 0.668 | Train Acc: 61.87%\n",
      "\t E 153 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 154 Train Loss: 0.666 | Train Acc: 61.93%\n",
      "\t E 154 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 155 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 155 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 156 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 156 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 157 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 157 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 158 Train Loss: 0.666 | Train Acc: 61.67%\n",
      "\t E 158 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 159 Train Loss: 0.667 | Train Acc: 61.54%\n",
      "\t E 159 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 160 Train Loss: 0.666 | Train Acc: 61.60%\n",
      "\t E 160 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 161 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 161 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 162 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 162 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 163 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 163 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 164 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 164 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 165 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 165 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 166 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 166 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 167 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 167 Test. Loss: 0.660 |  Test. Acc: 63.04%\n",
      "\t E 168 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 168 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 169 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 169 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 170 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 170 Test. Loss: 0.663 |  Test. Acc: 62.23%\n",
      "\t E 171 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 171 Test. Loss: 0.651 |  Test. Acc: 64.64%\n",
      "\t E 172 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 172 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 173 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 173 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 174 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 174 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 175 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 175 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 176 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 176 Test. Loss: 0.653 |  Test. Acc: 64.64%\n",
      "\t E 177 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 177 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 178 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 178 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 179 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 179 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 180 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 180 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 181 Train Loss: 0.666 | Train Acc: 61.93%\n",
      "\t E 181 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 182 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 182 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 183 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 183 Test. Loss: 0.656 |  Test. Acc: 63.84%\n",
      "\t E 184 Train Loss: 0.665 | Train Acc: 62.00%\n",
      "\t E 184 Test. Loss: 0.671 |  Test. Acc: 60.62%\n",
      "\t E 185 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 185 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 186 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 186 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 187 Train Loss: 0.668 | Train Acc: 61.80%\n",
      "\t E 187 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 188 Train Loss: 0.667 | Train Acc: 61.60%\n",
      "\t E 188 Test. Loss: 0.654 |  Test. Acc: 63.84%\n",
      "\t E 189 Train Loss: 0.665 | Train Acc: 61.87%\n",
      "\t E 189 Test. Loss: 0.664 |  Test. Acc: 62.23%\n",
      "\t E 190 Train Loss: 0.665 | Train Acc: 61.93%\n",
      "\t E 190 Test. Loss: 0.647 |  Test. Acc: 65.45%\n",
      "\t E 191 Train Loss: 0.667 | Train Acc: 61.67%\n",
      "\t E 191 Test. Loss: 0.659 |  Test. Acc: 63.04%\n",
      "\t E 192 Train Loss: 0.667 | Train Acc: 61.73%\n",
      "\t E 192 Test. Loss: 0.650 |  Test. Acc: 64.64%\n",
      "\t E 193 Train Loss: 0.665 | Train Acc: 61.80%\n",
      "\t E 193 Test. Loss: 0.655 |  Test. Acc: 63.84%\n",
      "\t E 194 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 194 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 195 Train Loss: 0.666 | Train Acc: 61.87%\n",
      "\t E 195 Test. Loss: 0.652 |  Test. Acc: 64.64%\n",
      "\t E 196 Train Loss: 0.666 | Train Acc: 61.80%\n",
      "\t E 196 Test. Loss: 0.649 |  Test. Acc: 65.45%\n",
      "\t E 197 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 197 Test. Loss: 0.648 |  Test. Acc: 65.45%\n",
      "\t E 198 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 198 Test. Loss: 0.644 |  Test. Acc: 66.25%\n",
      "\t E 199 Train Loss: 0.666 | Train Acc: 61.73%\n",
      "\t E 199 Test. Loss: 0.652 |  Test. Acc: 64.64%\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_apoe4.pickle\"\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "input_dim=X_train.shape[1]\n",
    "print(\"input dimensions\",input_dim)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "#print(X_test)\n",
    "\n",
    "\n",
    "model=Auto_encoder_model(input_dim,2) \n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01,weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "training_data=train_dataset(X_train,y_train)\n",
    "testing_data=train_dataset(X_test,y_test)\n",
    "\n",
    "training_dataloader=DataLoader(training_data,batch_size=16,shuffle=True)\n",
    "testing_dataloader=DataLoader(testing_data,batch_size=16,shuffle=True)\n",
    "EPOCHS=200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "\n",
    "    train_loss,train_acc=model_train(model,training_dataloader,optimizer,criterion,device)\n",
    "\n",
    "    test_loss,test_acc=model_evaluate(model,testing_dataloader,criterion,device)\n",
    "    print(f'\\t E {epoch} Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t E {epoch} Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f815e-4a60-47ce-86c3-b9d6e0995ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Acc: 64.64%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

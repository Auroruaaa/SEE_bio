{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262158a4-5c50-4fbb-8c90-c0428e60001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 19:19:02.847553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-15 19:19:02.867492: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-15 19:19:02.872902: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-15 19:19:02.886851: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 19:19:03.653684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e40e7e0-fd3d-4af8-abf5-8bfabb5d963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Autoencoder model as a subclass of the TensorFlow Model class\n",
    "\n",
    "class SimpleAutoencoder(Model):\n",
    "\tdef __init__(self,latent_dimensions , data_shape):\n",
    "\t\tsuper(SimpleAutoencoder, self).__init__()\n",
    "\t\tself.latent_dimensions = latent_dimensions\n",
    "\t\tself.data_shape = data_shape\n",
    "\n",
    "\t\t# Encoder architecture using a Sequential model\n",
    "\t\tself.encoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Flatten(),\n",
    "\t\t\tlayers.Dense(latent_dimensions, activation='relu', dtype='float32'),\n",
    "\t\t])\n",
    "\n",
    "\t\t# Decoder architecture using another Sequential model\n",
    "\t\tself.decoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Dense(tf.math.reduce_prod(data_shape), activation='sigmoid', dtype='float32'),\n",
    "\t\t\tlayers.Reshape(data_shape)\n",
    "\t\t])\n",
    "\n",
    "\t# Forward pass method defining the encoding and decoding steps\n",
    "\tdef call(self, input_data):\n",
    "\t\tencoded_data = self.encoder(input_data)\n",
    "\t\tdecoded_data = self.decoder(encoded_data)\n",
    "\t\treturn decoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fd2814-017d-4563-af9f-66cb9c77764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n",
      "2.2.2\n",
      "1.3.2\n",
      "(155, 10193, 1)\n",
      "(155,)\n",
      "(35, 10193, 1)\n",
      "(35,)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_amyloid.pickle\"\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "    \n",
    "# Normalize the data to the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "# Reshape the data to include the channel dimension (necessary for some models)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20704c71-4d60-44c0-acab-fc38c3cb5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7f3985124ef0>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# simple_autoencoder = simple_autoencoder.to(device)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m simple_autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m---> 16\u001b[0m \u001b[43msimple_autoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mSimpleAutoencoder.call\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m     23\u001b[0m \tencoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(input_data)\n\u001b[0;32m---> 24\u001b[0m \tdecoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m decoded_data\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7f3985124ef0>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Specifying the shape of the input data based on the testing dataset\n",
    "input_data_shape = X_test.shape[1:]\n",
    "\n",
    "# Specifying the dimensionality of the latent space\n",
    "latent_dimensions = 64\n",
    "\n",
    "# Creating an instance of the SimpleAutoencoder model\n",
    "simple_autoencoder = SimpleAutoencoder(latent_dimensions, input_data_shape)\n",
    "# simple_autoencoder = simple_autoencoder.to(device)\n",
    "\n",
    "simple_autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "simple_autoencoder.fit(X_train, X_train,\n",
    "                       epochs=5,\n",
    "                       batch_size = 16,\n",
    "                       shuffle=True,\n",
    "                       validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd336f4-aeef-49b0-a6b0-7791b71d6c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

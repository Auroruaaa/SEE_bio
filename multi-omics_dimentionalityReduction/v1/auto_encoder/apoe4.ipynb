{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1dc6ec-1dc0-4ed3-b24f-e371f1574004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef4547d-98ab-42c8-ab82-b6771b311dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n",
      "2.2.2\n",
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_apoe4.pickle\"\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(pd.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e26566-2092-4dd3-a736-7437c3eaa49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Autoencoder model as a subclass of the TensorFlow Model class\n",
    "\n",
    "class SimpleAutoencoder(Model):\n",
    "\tdef __init__(self,latent_dimensions , data_shape):\n",
    "\t\tsuper(SimpleAutoencoder, self).__init__()\n",
    "\t\tself.latent_dimensions = latent_dimensions\n",
    "\t\tself.data_shape = data_shape\n",
    "\n",
    "\t\t# Encoder architecture using a Sequential model\n",
    "\t\tself.encoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Flatten(),\n",
    "\t\t\tlayers.Dense(latent_dimensions, activation='relu'),\n",
    "\t\t])\n",
    "\n",
    "\t\t# Decoder architecture using another Sequential model\n",
    "\t\tself.decoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Dense(tf.math.reduce_prod(data_shape), activation='sigmoid'),\n",
    "\t\t\tlayers.Reshape(data_shape)\n",
    "\t\t])\n",
    "\n",
    "\t# Forward pass method defining the encoding and decoding steps\n",
    "\tdef call(self, input_data):\n",
    "\t\tencoded_data = self.encoder(input_data)\n",
    "\t\tdecoded_data = self.decoder(encoded_data)\n",
    "\t\treturn decoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe1893d-2bd4-4722-8aa6-92b03bf3f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 18:47:09.161816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 888 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:d0:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7fa4cb599170>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m simple_autoencoder \u001b[38;5;241m=\u001b[39m SimpleAutoencoder(latent_dimensions, input_data_shape)\n\u001b[1;32m     10\u001b[0m simple_autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m---> 12\u001b[0m \u001b[43msimple_autoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mSimpleAutoencoder.call\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m     23\u001b[0m \tencoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(input_data)\n\u001b[0;32m---> 24\u001b[0m \tdecoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m decoded_data\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling SimpleAutoencoder.call().\n\n\u001b[1mInvalid dtype: <property object at 0x7fa4cb599170>\u001b[0m\n\nArguments received by SimpleAutoencoder.call():\n  • input_data=tf.Tensor(shape=(None, 10193), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Extracting shape information from the testing dataset\n",
    "input_data_shape = X_test.shape[1:]\n",
    "\n",
    "# Specifying the dimensionality of the latent space\n",
    "latent_dimensions = 64\n",
    "\n",
    "# Creating an instance of the SimpleAutoencoder model\n",
    "simple_autoencoder = SimpleAutoencoder(latent_dimensions, input_data_shape)\n",
    "\n",
    "simple_autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "simple_autoencoder.fit(X_train, y_train,\n",
    "\t\t\t\tepochs=1,\n",
    "\t\t\t\tshuffle=True,\n",
    "\t\t\t\tvalidation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae737061-ce7d-40ad-a7d5-6d1a7b6e94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 10193)\n",
      "(683,)\n",
      "(151, 10193)\n",
      "(151,)\n",
      "[1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1\n",
      " 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0\n",
      " 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1\n",
      " 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0\n",
      " 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0]\n",
      "<class 'numpy.ndarray'>\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[1:])\n",
    "print(type(y_train))\n",
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b79438-5811-48d8-9d08-3a05a23d6662",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Create the model instance\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m autoencoder_model \u001b[38;5;241m=\u001b[39m \u001b[43mAuto_encoder_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m     66\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mAuto_encoder_model.__init__\u001b[0;34m(self, input_dim, output_dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_fc12 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_fc13 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_fc \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_mid \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.05\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Ensure the device is set to CPU and import necessary modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Define the PyTorch Autoencoder model class\n",
    "class Auto_encoder_model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, 5000)\n",
    "        self.hidden_fc = nn.Linear(5000, 4000)\n",
    "        self.hidden_fc2 = nn.Linear(4000, 3000)\n",
    "        self.hidden_fc9 = nn.Linear(3000, 2000)\n",
    "        self.hidden_fc10 = nn.Linear(2000, 1000)\n",
    "        self.hidden_fc11 = nn.Linear(1000, 500)\n",
    "        self.hidden_fc12 = nn.Linear(500, 200)\n",
    "        self.hidden_fc13 = nn.Linear(200, 50)\n",
    "        self.output_fc = nn.Linear(50, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dropout_mid = nn.Dropout(0.05)\n",
    "        self.dropout_small = nn.Dropout(0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x1 = nn.functional.relu(self.input_fc(x))\n",
    "        x1 = self.dropout_mid(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc(x1))\n",
    "        x1 = self.dropout_mid(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc2(x1))\n",
    "        x1 = self.dropout_mid(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc9(x1))\n",
    "        x1 = self.dropout_mid(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc10(x1))\n",
    "        x1 = self.dropout_mid(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc11(x1))\n",
    "        x1 = self.dropout_small(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc12(x1))\n",
    "        x1 = self.dropout_small(x1)\n",
    "        x1 = nn.functional.relu(self.hidden_fc13(x1))\n",
    "        x1 = self.dropout_small(x1)\n",
    "        x1 = self.output_fc(x1)\n",
    "        return x1\n",
    "\n",
    "# Load dataset\n",
    "with open(\"dataset_amyloid.pickle\", 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define model parameters\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape\n",
    "\n",
    "# Create the model instance\n",
    "autoencoder_model = Auto_encoder_model(input_dim, output_dim).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder_model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = autoencoder_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluating the model\n",
    "autoencoder_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = autoencoder_model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626aac7-84d6-4a26-8bc1-8afe6e264d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47f2616-6dc7-455d-aad3-88bac044d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from biom import Table`\n",
    "from gemelli.rpca import rpca\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f874e247-64c9-4e1c-9fe1-85451bbb0f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 355)\n",
      "    sample_name      NACCID Kit.Number  Specimen.Bar.Code Visit  FORMVER  \\\n",
      "0  15448.582342  NACC849121     376222            5823422    Y1      3.2   \n",
      "1  15448.582709  NACC918252     376177            5827089    Y1      3.2   \n",
      "2  15448.583516  NACC420113     376232            5835163    Y1      3.2   \n",
      "3  15448.594676  NACC454008     404184            5946764    Y1      3.2   \n",
      "4  15448.421452  NACC329271     420091           42145155    Y2      3.0   \n",
      "\n",
      "   NACCVNUM  SEX  HISPANIC  RACE  ...    tube_id  turbidity_grade  uom  visit  \\\n",
      "0         3    1         0     1  ...  363236903              NaN  NaN     Y1   \n",
      "1         4    1         0     1  ...  363195322              NaN  NaN     Y1   \n",
      "2         9    2         0     1  ...  363183648              NaN  NaN     Y1   \n",
      "3         4    2         0     1  ...  363236757              NaN  NaN     Y1   \n",
      "4         3    2         0     2  ...  363236670              NaN  NaN     Y2   \n",
      "\n",
      "   well_id  year_of_collection     yob  amyloid  diagnosis        apoe4  \n",
      "0      NaN              2021.0  1949.0      NaN     Normal      Carrier  \n",
      "1      NaN              2021.0  1947.0      NaN     Normal  Non-carrier  \n",
      "2      NaN              2021.0  1940.0      NaN     Normal  Non-carrier  \n",
      "3      NaN              2021.0  1954.0      NaN     Normal      Carrier  \n",
      "4      NaN              2022.0  1954.0      NaN     Normal      Carrier  \n",
      "\n",
      "[5 rows x 355 columns]\n",
      "Table shape: (1102, 1312)\n",
      "# Constructed from biom file\n",
      "#OTU ID\t15448.0005635586\t15448.0005643690\t15448.0005671650\t15448.0005700235\t15448.0005704913\n",
      "G000006865\t13.0\t5.0\t20.0\t10.0\t4.0\n",
      "G000006925\t13.0\t127.0\t1.0\t171.0\t921.0\n",
      "G000007325\t0.0\t1.0\t0.0\t1.0\t0.0\n",
      "G000007465\t0.0\t0.0\t0.0\t5.0\t0.0\n",
      "G000007525\t0.0\t0.0\t28.0\t35.0\t30.0\n"
     ]
    }
   ],
   "source": [
    "meta_path = \"./adrc_full_metadata.csv\"\n",
    "table_path = \"./adrc_full_table.biom\"\n",
    "table_path = \"./../metadata/adrc_coverage_filtered_table.biom\"\n",
    "meta = pd.read_csv(meta_path)\n",
    "table = biom.load_table(table_path)\n",
    "\n",
    "print(meta.shape)\n",
    "print(meta.head(5))\n",
    "print(f\"Table shape: {table.shape}\")\n",
    "print(table.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3250c2f4-4c0e-45ec-944d-4e809cc33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BIOM table to a pandas DataFrame (OTUs as rows, samples as columns)\n",
    "biom_df = pd.DataFrame(table.matrix_data.toarray(), index=table.ids(axis='observation'), columns=table.ids(axis='sample'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9361d947-cce6-408b-8c13-9fd008aa1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Check general information about the table\n",
    "# print(\"Table dimensions (rows, columns):\", biom_df.shape)\n",
    "# print(\"Maximum value in the table:\", biom_df.values.max())\n",
    "# print(\"Minimum value in the table:\", biom_df.values.min())\n",
    "# print(\"Mean value in the table:\", biom_df.values.mean())\n",
    "# print(\"Standard deviation in the table:\", biom_df.values.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55ea9de-eee2-46e2-8522-0aecb950e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of binary features: 0\n",
      "Number of numerical features: 1102\n"
     ]
    }
   ],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "\n",
    "binary_features = binary_features.drop(columns=['feature_type'])\n",
    "numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "\n",
    "print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae9e768-2e1c-496a-9c9e-5eda92437a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            15448.0005635586  15448.0005643690  15448.0005671650  \\\n",
      "G000006865          0.000829          0.000319      1.274616e-03   \n",
      "G000006925          0.000012          0.000120      9.487189e-07   \n",
      "G000007325          0.000000          0.000535      0.000000e+00   \n",
      "G000007465          0.000000          0.000000      0.000000e+00   \n",
      "G000007525          0.000000          0.000000      2.506277e-05   \n",
      "...                      ...               ...               ...   \n",
      "G902377395          0.013391          0.004304      1.960784e-02   \n",
      "G902385285          0.018129          0.057304      1.898153e-02   \n",
      "G902387315          0.005682          0.002308      3.866189e-02   \n",
      "G902406265          0.002646          0.000075      1.117818e-04   \n",
      "G902765685          0.000000          0.000007      3.529416e-06   \n",
      "\n",
      "            15448.0005700235  15448.0005704913  15448.0005704938  \\\n",
      "G000006865          0.000637          0.000255          0.000000   \n",
      "G000006925          0.000162          0.000874          0.001650   \n",
      "G000007325          0.000535          0.000000          0.000535   \n",
      "G000007465          0.002489          0.000000          0.000000   \n",
      "G000007525          0.000031          0.000027          0.000000   \n",
      "...                      ...               ...               ...   \n",
      "G902377395          0.007652          0.030129          0.005739   \n",
      "G902385285          0.004061          0.014560          0.038635   \n",
      "G902387315          0.033046          0.005055          0.003099   \n",
      "G902406265          0.000075          0.000671          0.000484   \n",
      "G902765685          0.000000          0.000004          0.000014   \n",
      "\n",
      "            15448.0005707913  15448.0005714515  15448.0005728264  \\\n",
      "G000006865          0.000382      0.000000e+00          0.000127   \n",
      "G000006925          0.000002      9.487189e-07          0.000009   \n",
      "G000007325          0.000000      0.000000e+00          0.000000   \n",
      "G000007465          0.000000      4.977601e-04          0.000000   \n",
      "G000007525          0.000302      1.790198e-05          0.001026   \n",
      "...                      ...               ...               ...   \n",
      "G902377395          0.003348      7.651841e-03          0.006217   \n",
      "G902385285          0.020496      3.717729e-02          0.032131   \n",
      "G902387315          0.002077      1.946282e-02          0.002824   \n",
      "G902406265          0.000112      2.980848e-04          0.005328   \n",
      "G902765685          0.000004      0.000000e+00          0.000000   \n",
      "\n",
      "            15448.0005728304  ...  15448.43049648  15448.43051236  \\\n",
      "G000006865          0.000191  ...        0.000446        0.005545   \n",
      "G000006925          0.000031  ...        0.015531        0.000107   \n",
      "G000007325          0.000000  ...        0.000535        0.000000   \n",
      "G000007465          0.002987  ...        0.000000        0.000000   \n",
      "G000007525          0.002936  ...        0.000005        0.000374   \n",
      "...                      ...  ...             ...             ...   \n",
      "G902377395          0.012434  ...        0.129125        0.046868   \n",
      "G902385285          0.026224  ...        0.087201        0.039572   \n",
      "G902387315          0.002813  ...        0.077368        0.011429   \n",
      "G902406265          0.005850  ...        0.013339        0.001639   \n",
      "G902765685          0.000000  ...        0.000000        0.000007   \n",
      "\n",
      "            15448.43051259  15448.43051286  15448.43051306  15448.43105150  \\\n",
      "G000006865    2.549232e-04        0.006246        0.004334        0.000701   \n",
      "G000006925    9.487189e-07        0.004720        0.000289        0.000040   \n",
      "G000007325    0.000000e+00        0.000535        0.000000        0.000000   \n",
      "G000007465    0.000000e+00        0.055749        0.002489        0.000996   \n",
      "G000007525    2.314189e-02        0.000019        0.006704        0.025038   \n",
      "...                    ...             ...             ...             ...   \n",
      "G902377395    1.793400e-01        0.079388        0.076997        0.083214   \n",
      "G902385285    8.044192e-02        0.021225        0.060921        0.052060   \n",
      "G902387315    4.844275e-02        0.190584        0.035486        0.063817   \n",
      "G902406265    2.384678e-03        0.002608        0.040800        0.002310   \n",
      "G902765685    0.000000e+00        0.000000        0.000000        0.000000   \n",
      "\n",
      "            15448.5823422  15448.5827089  15448.5835163  15448.5946764  \n",
      "G000006865       0.000127       0.000956       0.000000       0.045631  \n",
      "G000006925       0.002403       0.000896       0.000273       0.000062  \n",
      "G000007325       0.000000       0.000000       0.000000       0.000000  \n",
      "G000007465       0.000000       0.000498       0.001493       0.004978  \n",
      "G000007525       0.003742       0.043428       0.000000       0.000002  \n",
      "...                   ...            ...            ...            ...  \n",
      "G902377395       0.050215       0.039216       0.047346       0.107604  \n",
      "G902385285       0.023393       0.083528       0.056954       0.106031  \n",
      "G902387315       0.326032       0.025892       0.037255       0.076038  \n",
      "G902406265       0.002571       0.001677       0.009501       0.001975  \n",
      "G902765685       0.000000       0.000000       0.000000       0.000000  \n",
      "\n",
      "[1102 rows x 1312 columns]\n"
     ]
    }
   ],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = pd.DataFrame(scaler.fit_transform(numerical_features.T).T, index=numerical_features.index, columns=numerical_features.columns)\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86556f20-b2cf-4160-adb9-c6e2c8a56dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = scaler.fit_transform(numerical_features.T).T\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474d8688-0ad3-41fb-8d7b-5cf7bd04a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += 1e-10\n",
    "sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "table_scaled = Table(scaled, feature_ids, sample_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5008b3f-1a82-499c-897f-5c8726ff1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 128  # Number of components to reduce to\n",
    "rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "ordination, distance = rpca_results\n",
    "sample_scores = ordination.samples  # Scores for samples\n",
    "feature_scores = ordination.features  # Scores for features\n",
    "\n",
    "X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "\n",
    "mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "print(f\"Reconstruction MSE: {mse}\")\n",
    "\n",
    "print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "print(f\"Reconstructed data shape: {X_reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "81136b2e-6364-43c8-a7df-35f846aed677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction MSE: 0.003958728646643008\n",
    "# Sample scores shape: (1312, 3)\n",
    "# Feature scores shape: (1102, 3)\n",
    "# Original scaled data shape: (1312, 1102)\n",
    "# Reconstructed data shape: (1312, 1102)\n",
    "\n",
    "\n",
    "# Reconstruction MSE: 0.0033221211643852722\n",
    "# Sample scores shape: (1312, 10)\n",
    "# Feature scores shape: (8448, 10)\n",
    "# Original scaled data shape: (1312, 8448)\n",
    "# Reconstructed data shape: (1312, 8448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "dbafb11d-9636-4cad-873c-8ba30e505315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ordination)\n",
    "# print(distance)\n",
    "\n",
    "# Ordination results:\n",
    "# \tMethod: (Robust Aitchison) RPCA Biplot (rpca_biplot)\n",
    "# \tEigvals: 3\n",
    "# \tProportion explained: 3\n",
    "# \tFeatures: 1102x3\n",
    "# \tSamples: 1312x3\n",
    "# \tBiplot Scores: N/A\n",
    "# \tSample constraints: N/A\n",
    "# \tFeature IDs: 'G000006865', 'G000006925', 'G000007325', 'G000007465', 'G000007525', ...\n",
    "# \tSample IDs: '15448.0005635586', '15448.0005643690', '15448.0005671650', '15448.0005700235', ...\n",
    "# 1312x1312 distance matrix\n",
    "# IDs:\n",
    "# '15448.0005635586', '15448.0005643690', '15448.0005671650', '15448.0005700235', ...\n",
    "# Data:\n",
    "# [[0.         2.08392107 0.56944807 ... 2.39861693 1.28328955 2.31825922]\n",
    "#  [2.08392107 0.         1.57075643 ... 0.9076768  1.28762466 0.98842086]\n",
    "#  [0.56944807 1.57075643 0.         ... 1.82917398 1.08186416 1.75242724]\n",
    "#  ...\n",
    "#  [2.39861693 0.9076768  1.82917398 ... 0.         2.0035645  0.24021381]\n",
    "#  [1.28328955 1.28762466 1.08186416 ... 2.0035645  0.         1.97177064]\n",
    "#  [2.31825922 0.98842086 1.75242724 ... 0.24021381 1.97177064 0.        ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6752e67b-ff23-40b1-9fa8-62f8a772c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using reduced scaled numerical dataset\n",
    "reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9b440b0b-3220-46de-a482-d523b1aaf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using both binary and reduced numerical dataset\n",
    "# reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "\n",
    "# binary_transposed = binary_features.T \n",
    "# # reduced_df.index = reduced_df.index.astype(float)\n",
    "# # print(reduced_df.index)\n",
    "# # print(binary_transposed.index)\n",
    "# # print(\"Do sample names match?\", (reduced_df.index == binary_transposed.index).all())\n",
    "# combined_df = pd.concat([reduced_df, binary_transposed], axis=1)\n",
    "# combined_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "# meta_df = meta.set_index('sample_name')\n",
    "\n",
    "# merged_df = combined_df.join(metadata_df[['host_age']], how='inner')\n",
    "# cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# # print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# # print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# # # Original dataset shape: (1312, 1749)\n",
    "# # # Cleaned dataset shape: (1301, 1749)\n",
    "\n",
    "# X = cleaned_df.drop(columns=['host_age'])\n",
    "# Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1ca04a73-b8b8-4341-8fc0-24202551e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 59.808153281084984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b7b456ac-8a26-4758-9630-5771d95ad414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 62.939483908045986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "28a56e40-9e53-4884-91da-daccc97c87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor MSE: 59.78929765458566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "29a5167e-1752-4aa4-b239-474421634e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 64.94144790232647\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94412bce-5232-4b50-9506-fc81cd05d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------RPCA Num ONLY--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003958728646643008\n",
    "Cleaned dataset shape: (1301, 4)\n",
    "Linear Regression MSE: 68.19986181183467\n",
    "Random Forest MSE: 75.95139961685823\n",
    "MLP Regressor MSE: 68.22414791217268\n",
    "XGBoost MSE: 76.82236484129864\n",
    "\n",
    "Dim = 10\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003946154448124425\n",
    "Linear Regression MSE: 59.808153281084984\n",
    "Random Forest MSE: 62.939483908045986\n",
    "MLP Regressor MSE: 59.78929765458566\n",
    "XGBoost MSE: 64.94144790232647\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b7f5d3eb-16ff-40c8-b434-e6b6359106f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01743150302309283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_transposed = numerical_features.T\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data_transposed)\n",
    "\n",
    "reduced_dim = 512\n",
    "pca = PCA(n_components=reduced_dim, svd_solver='auto')\n",
    "pca_reduced = pca.fit_transform(standardized_data)\n",
    "pca_reconstructed = pca.inverse_transform(pca_reduced)\n",
    "\n",
    "mse_pca = mean_squared_error(standardized_data, pca_reconstructed)\n",
    "\n",
    "print(mse_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "844b7905-19dc-4d61-960a-6a2f9e11c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.DataFrame(pca_reduced, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "79d15b9d-2d84-49e0-b886-e00517a9d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 580.8346541828049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "39eeaee6-6905-4886-b637-e6cf45dde8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 63.36988850574713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0f93ad2a-89d5-4fe6-9cc6-0427c5b0d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor MSE: 911.1563581922785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5bba6f61-48e8-4256-91d0-5c2200489221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 67.18452645782199\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d9307088-2a94-4aa0-9c4c-d1b5096176af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n--------PCA--------\\nDim = 128\\nReconstruction MSE(full): 0.32280275488908244\\nCleaned dataset shape: (1301, 129)\\nLinear Regression MSE: 2841.559584303109\\nRandom Forest MSE: 66.89663639846744\\nMLP Regressor MSE: 895.1086733724248\\nXGBoost MSE: 70.36381670902817\\n\\nReconstruction MSE(auto): 0.32696752866827633\\nLinear Regression MSE: 97.59366339211996\\nRandom Forest MSE: 65.1517490421456\\nMLP Regressor MSE: 970.4559274788406\\nXGBoost MSE: 64.4298729789169\\n\\nDim = 512\\nReconstruction MSE(full): 0.09005376802270713\\nLinear Regression MSE: 2841.559584303109\\nRandom Forest MSE: 66.89663639846744\\nMLP Regressor MSE: 895.1086733724248\\nXGBoost MSE: 70.36381670902817\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "--------PCA--------\n",
    "Dim = 128\n",
    "Reconstruction MSE(full): 0.32280275488908244\n",
    "Cleaned dataset shape: (1301, 129)\n",
    "Linear Regression MSE: 2841.559584303109\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 895.1086733724248\n",
    "XGBoost MSE: 70.36381670902817\n",
    "\n",
    "Reconstruction MSE(auto): 0.32696752866827633\n",
    "Linear Regression MSE: 97.59366339211996\n",
    "Random Forest MSE: 64.57761494252874\n",
    "MLP Regressor MSE: 970.4559274788406\n",
    "XGBoost MSE: 64.4298729789169\n",
    "\n",
    "Dim = 512\n",
    "Reconstruction MSE(full): 0.01719558259971444\n",
    "Linear Regression MSE: 551.90068430994\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 811.2290273839908\n",
    "XGBoost MSE: 69.61207270397696\n",
    "\n",
    "Reconstruction MSE(auto): 0.01743150302309283\n",
    "Linear Regression MSE: 580.8346541828049\n",
    "Random Forest MSE: 63.36988850574713\n",
    "MLP Regressor MSE: 911.1563581922785\n",
    "XGBoost MSE: 67.18452645782199\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "04eadbfa-c3b0-42bd-a315-27fd95d30794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "21.0\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df['host_age'].max())\n",
    "print(cleaned_df['host_age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59cc7c-4c26-49e6-9f0f-cbaebc9641de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

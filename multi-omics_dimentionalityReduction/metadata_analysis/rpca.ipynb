{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47f2616-6dc7-455d-aad3-88bac044d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from biom import Table\n",
    "from gemelli.rpca import rpca\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f874e247-64c9-4e1c-9fe1-85451bbb0f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 355)\n",
      "    sample_name      NACCID Kit.Number  Specimen.Bar.Code Visit  FORMVER  \\\n",
      "0  15448.582342  NACC849121     376222            5823422    Y1      3.2   \n",
      "1  15448.582709  NACC918252     376177            5827089    Y1      3.2   \n",
      "2  15448.583516  NACC420113     376232            5835163    Y1      3.2   \n",
      "3  15448.594676  NACC454008     404184            5946764    Y1      3.2   \n",
      "4  15448.421452  NACC329271     420091           42145155    Y2      3.0   \n",
      "\n",
      "   NACCVNUM  SEX  HISPANIC  RACE  ...    tube_id  turbidity_grade  uom  visit  \\\n",
      "0         3    1         0     1  ...  363236903              NaN  NaN     Y1   \n",
      "1         4    1         0     1  ...  363195322              NaN  NaN     Y1   \n",
      "2         9    2         0     1  ...  363183648              NaN  NaN     Y1   \n",
      "3         4    2         0     1  ...  363236757              NaN  NaN     Y1   \n",
      "4         3    2         0     2  ...  363236670              NaN  NaN     Y2   \n",
      "\n",
      "   well_id  year_of_collection     yob  amyloid  diagnosis        apoe4  \n",
      "0      NaN              2021.0  1949.0      NaN     Normal      Carrier  \n",
      "1      NaN              2021.0  1947.0      NaN     Normal  Non-carrier  \n",
      "2      NaN              2021.0  1940.0      NaN     Normal  Non-carrier  \n",
      "3      NaN              2021.0  1954.0      NaN     Normal      Carrier  \n",
      "4      NaN              2022.0  1954.0      NaN     Normal      Carrier  \n",
      "\n",
      "[5 rows x 355 columns]\n",
      "Table shape: (10193, 1312)\n"
     ]
    }
   ],
   "source": [
    "meta_path = \"./adrc_full_metadata.csv\"\n",
    "table_path = \"./adrc_full_table.biom\"\n",
    "# table_path = \"./feature_reduction/metadata/adrc_coverage_filtered_table.biom\"\n",
    "meta = pd.read_csv(meta_path)\n",
    "table = biom.load_table(table_path)\n",
    "\n",
    "print(meta.shape)\n",
    "print(meta.head(5))\n",
    "print(f\"Table shape: {table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3250c2f4-4c0e-45ec-944d-4e809cc33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BIOM table to a pandas DataFrame (OTUs as rows, samples as columns)\n",
    "biom_df = pd.DataFrame(table.matrix_data.toarray(), index=table.ids(axis='observation'), columns=table.ids(axis='sample'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70022f71-ab0d-4dc1-8a40-464e40dd9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            15448.0005635586  15448.0005643690  15448.0005671650  \\\n",
      "G000005825               0.0               0.0               0.0   \n",
      "G000006605               0.0               0.0               0.0   \n",
      "G000006725               0.0               0.0               0.0   \n",
      "G000006745               0.0               0.0               0.0   \n",
      "G000006785               0.0               0.0               1.0   \n",
      "\n",
      "            15448.0005700235  15448.0005704913  15448.0005704938  \\\n",
      "G000005825               1.0               0.0               0.0   \n",
      "G000006605               0.0               0.0               0.0   \n",
      "G000006725               0.0               0.0               0.0   \n",
      "G000006745               0.0               0.0               0.0   \n",
      "G000006785               3.0               1.0               0.0   \n",
      "\n",
      "            15448.0005707913  15448.0005714515  15448.0005728264  \\\n",
      "G000005825               0.0               0.0               0.0   \n",
      "G000006605               1.0               0.0               0.0   \n",
      "G000006725               0.0               0.0               0.0   \n",
      "G000006745               0.0               0.0               0.0   \n",
      "G000006785               0.0               1.0               0.0   \n",
      "\n",
      "            15448.0005728304  ...  15448.43049648  15448.43051236  \\\n",
      "G000005825               0.0  ...             0.0             0.0   \n",
      "G000006605               0.0  ...             0.0             0.0   \n",
      "G000006725               0.0  ...             0.0             0.0   \n",
      "G000006745               0.0  ...             0.0             0.0   \n",
      "G000006785               1.0  ...             1.0             0.0   \n",
      "\n",
      "            15448.43051259  15448.43051286  15448.43051306  15448.43105150  \\\n",
      "G000005825             0.0             1.0             1.0             0.0   \n",
      "G000006605             0.0             0.0             0.0             0.0   \n",
      "G000006725             0.0             0.0             0.0             0.0   \n",
      "G000006745             0.0             0.0             0.0             0.0   \n",
      "G000006785             3.0            84.0            23.0             3.0   \n",
      "\n",
      "            15448.5823422  15448.5827089  15448.5835163  15448.5946764  \n",
      "G000005825            0.0            1.0            0.0            0.0  \n",
      "G000006605            5.0            0.0            0.0            0.0  \n",
      "G000006725            0.0            0.0            0.0            0.0  \n",
      "G000006745            0.0            0.0            0.0            0.0  \n",
      "G000006785            0.0            5.0            7.0            6.0  \n",
      "\n",
      "[5 rows x 1312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(biom_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9361d947-cce6-408b-8c13-9fd008aa1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check general information about the table\n",
    "# print(\"Table dimensions (rows, columns):\", biom_df.shape)\n",
    "# print(\"Maximum value in the table:\", biom_df.values.max())\n",
    "# print(\"Minimum value in the table:\", biom_df.values.min())\n",
    "# print(\"Mean value in the table:\", biom_df.values.mean())\n",
    "# print(\"Standard deviation in the table:\", biom_df.values.std())\n",
    "\n",
    "# # Optionally, you can get descriptive statistics (min, max, mean, etc. for each column)\n",
    "# print(\"Descriptive statistics:\\n\", biom_df.describe())\n",
    "\n",
    "# Table dimensions (rows, columns): (10193, 1312)\n",
    "# Maximum value in the table: 8599868.0\n",
    "# Minimum value in the table: 0.0\n",
    "# Mean value in the table: 683.7085010067885\n",
    "# Standard deviation in the table: 19481.296853288957\n",
    "# Descriptive statistics:\n",
    "#         15448.0005635586  15448.0005643690  15448.0005671650  15448.0005700235  \\\n",
    "# count      10193.000000      1.019300e+04      10193.000000      10193.000000   \n",
    "# mean         120.188070      3.704773e+02        376.374080        123.804670   \n",
    "# std         2432.148599      1.271535e+04       6914.365337       2666.197215   \n",
    "# min            0.000000      0.000000e+00          0.000000          0.000000   \n",
    "# 25%            0.000000      0.000000e+00          0.000000          0.000000   \n",
    "# 50%            0.000000      0.000000e+00          0.000000          0.000000   \n",
    "# 75%            0.000000      0.000000e+00          0.000000          0.000000   \n",
    "# max       175514.000000      1.107260e+06     310734.000000     230160.000000   \n",
    "\n",
    "#        15448.0005704913  15448.0005704938  15448.0005707913  15448.0005714515  \\\n",
    "# count      10193.000000      10193.000000      10193.000000      10193.000000   \n",
    "# mean         240.527813        258.992838        158.010203        225.403316   \n",
    "# std         6288.504698       6798.884678       4678.156618       6603.885954   \n",
    "# min            0.000000          0.000000          0.000000          0.000000   \n",
    "# 25%            0.000000          0.000000          0.000000          0.000000   \n",
    "# 50%            0.000000          0.000000          0.000000          0.000000   \n",
    "# 75%            0.000000          0.000000          0.000000          0.000000   \n",
    "# max       573808.000000     473105.000000     401999.000000     605058.000000   \n",
    "\n",
    "#        15448.0005728264  15448.0005728304  ...  15448.43049648  \\\n",
    "# count      10193.000000      10193.000000  ...    1.019300e+04   \n",
    "# mean         286.159031        349.248406  ...    1.553244e+03   \n",
    "# std         7258.375894       8228.733100  ...    2.695542e+04   \n",
    "# min            0.000000          0.000000  ...    0.000000e+00   \n",
    "# 25%            0.000000          0.000000  ...    0.000000e+00   \n",
    "# 50%            0.000000          0.000000  ...    0.000000e+00   \n",
    "# 75%            0.000000          0.000000  ...    1.000000e+00   \n",
    "# max       560804.000000     574964.000000  ...    1.916519e+06   \n",
    "\n",
    "#        15448.43051236  15448.43051259  15448.43051286  15448.43051306  \\\n",
    "# count    10193.000000    1.019300e+04    10193.000000    1.019300e+04   \n",
    "# mean       574.905425    1.196409e+03      611.245463    1.361047e+03   \n",
    "# std      11065.953035    3.049383e+04     8212.387482    2.235665e+04   \n",
    "# min          0.000000    0.000000e+00        0.000000    0.000000e+00   \n",
    "# 25%          0.000000    0.000000e+00        0.000000    0.000000e+00   \n",
    "# 50%          0.000000    0.000000e+00        0.000000    0.000000e+00   \n",
    "# 75%          0.000000    0.000000e+00        1.000000    1.000000e+00   \n",
    "# max     587838.000000    2.875161e+06   464469.000000    1.753825e+06   \n",
    "\n",
    "#        15448.43105150  15448.5823422  15448.5827089  15448.5835163  \\\n",
    "# count    10193.000000   10193.000000   1.019300e+04   10193.000000   \n",
    "# mean       607.535858     967.961640   9.991206e+02     966.035024   \n",
    "# std       8956.249757   12099.219172   1.833273e+04   17898.826230   \n",
    "# min          0.000000       0.000000   0.000000e+00       0.000000   \n",
    "# 25%          0.000000       0.000000   0.000000e+00       0.000000   \n",
    "# 50%          0.000000       0.000000   0.000000e+00       0.000000   \n",
    "# 75%          0.000000       1.000000   0.000000e+00       0.000000   \n",
    "# max     501124.000000  394460.000000   1.320731e+06  943580.000000   \n",
    "\n",
    "#        15448.5946764  \n",
    "# count   1.019300e+04  \n",
    "# mean    1.315904e+03  \n",
    "# std     2.524127e+04  \n",
    "# min     0.000000e+00  \n",
    "# 25%     0.000000e+00  \n",
    "# 50%     0.000000e+00  \n",
    "# 75%     1.000000e+00  \n",
    "# max     1.520083e+06  \n",
    "\n",
    "# [8 rows x 1312 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e55ea9de-eee2-46e2-8522-0aecb950e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of binary features: 1745\n",
      "Number of numerical features: 8448\n"
     ]
    }
   ],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "\n",
    "binary_features = binary_features.drop(columns=['feature_type'])\n",
    "numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "\n",
    "print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aae9e768-2e1c-496a-9c9e-5eda92437a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_d = numerical_features.copy()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "# scaled = pd.DataFrame(scaler.fit_transform(numerical_features.T).T, index=numerical_features.index, columns=numerical_features.columns)\n",
    "\n",
    "# # print(\"Scaled Numerical Dataset:\")\n",
    "# # print(scaled.head())\n",
    "# print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86556f20-b2cf-4160-adb9-c6e2c8a56dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = scaler.fit_transform(numerical_features.T).T\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "474d8688-0ad3-41fb-8d7b-5cf7bd04a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += 1e-10\n",
    "sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "table_scaled = Table(scaled, feature_ids, sample_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b5008b3f-1a82-499c-897f-5c8726ff1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction MSE: 0.003322121164396924\n",
      "Sample scores shape: (1312, 10)\n",
      "Feature scores shape: (8448, 10)\n",
      "Original scaled data shape: (1312, 8448)\n",
      "Reconstructed data shape: (1312, 8448)\n"
     ]
    }
   ],
   "source": [
    "dim = 10  # Number of components to reduce to\n",
    "rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "ordination, distance = rpca_results\n",
    "sample_scores = ordination.samples  # Scores for samples\n",
    "feature_scores = ordination.features  # Scores for features\n",
    "\n",
    "X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "\n",
    "mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "print(f\"Reconstruction MSE: {mse}\")\n",
    "\n",
    "print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "print(f\"Reconstructed data shape: {X_reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "81136b2e-6364-43c8-a7df-35f846aed677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction MSE: 0.003335061983338765\n",
    "# Sample scores shape: (1312, 3)\n",
    "# Feature scores shape: (8448, 3)\n",
    "# Original scaled data shape: (1312, 8448)\n",
    "# Reconstructed data shape: (1312, 8448)\n",
    "\n",
    "# Reconstruction MSE: 0.0033221211643852722\n",
    "# Sample scores shape: (1312, 10)\n",
    "# Feature scores shape: (8448, 10)\n",
    "# Original scaled data shape: (1312, 8448)\n",
    "# Reconstructed data shape: (1312, 8448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dbafb11d-9636-4cad-873c-8ba30e505315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ordination)\n",
    "# print(distance)\n",
    "\n",
    "# # Ordination results:\n",
    "# # \tMethod: (Robust Aitchison) RPCA Biplot (rpca_biplot)\n",
    "# # \tEigvals: 3\n",
    "# # \tProportion explained: 3\n",
    "# # \tFeatures: 8448x3\n",
    "# # \tSamples: 1312x3\n",
    "# # \tBiplot Scores: N/A\n",
    "# # \tSample constraints: N/A\n",
    "# # \tFeature IDs: 'G000005825', 'G000006605', 'G000006725', 'G000006745', 'G000006785', ...\n",
    "# # \tSample IDs: '15448.0005635586', '15448.0005643690', '15448.0005671650', '15448.0005700235', ...\n",
    "# # 1312x1312 distance matrix\n",
    "# # IDs:\n",
    "# # '15448.0005635586', '15448.0005643690', '15448.0005671650', '15448.0005700235', ...\n",
    "# # Data:\n",
    "# # [[0.         0.78449788 0.64521211 ... 1.71529196 2.67520481 2.77895356]\n",
    "# #  [0.78449788 0.         1.02136413 ... 1.8786006  2.6711468  2.79996043]\n",
    "# #  [0.64521211 1.02136413 0.         ... 1.07032847 2.04138511 2.14052415]\n",
    "# #  ...\n",
    "# #  [1.71529196 1.8786006  1.07032847 ... 0.         1.00700367 1.08827712]\n",
    "# #  [2.67520481 2.6711468  2.04138511 ... 1.00700367 0.         0.14763164]\n",
    "# #  [2.77895356 2.79996043 2.14052415 ... 1.08827712 0.14763164 0.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6752e67b-ff23-40b1-9fa8-62f8a772c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using reduced scaled numerical dataset\n",
    "reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9b440b0b-3220-46de-a482-d523b1aaf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both binary and reduced numerical dataset\n",
    "reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "\n",
    "binary_transposed = binary_features.T \n",
    "# reduced_df.index = reduced_df.index.astype(float)\n",
    "# print(reduced_df.index)\n",
    "# print(binary_transposed.index)\n",
    "# print(\"Do sample names match?\", (reduced_df.index == binary_transposed.index).all())\n",
    "combined_df = pd.concat([reduced_df, binary_transposed], axis=1)\n",
    "combined_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = combined_df.join(metadata_df[['host_age']], how='inner')\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# # Original dataset shape: (1312, 1749)\n",
    "# # Cleaned dataset shape: (1301, 1749)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1ca04a73-b8b8-4341-8fc0-24202551e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 3.435636078812604e+27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b7b456ac-8a26-4758-9630-5771d95ad414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 68.0639318007663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "28a56e40-9e53-4884-91da-daccc97c87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor MSE: 170.48459862383126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "29a5167e-1752-4aa4-b239-474421634e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 66.91970884783616\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94412bce-5232-4b50-9506-fc81cd05d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------RPCA Num ONLY--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003335061983338765\n",
    "Cleaned dataset shape: (1301, 4)\n",
    "Linear Regression MSE: 68.21386741357641\n",
    "Random Forest MSE: 74.40174406130268\n",
    "MLP Regressor MSE: 68.23618351926648\n",
    "XGBoost MSE: 73.97999390869334\n",
    "\n",
    "Dim = 10\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.0033221211643852722\n",
    "Linear Regression MSE: 64.54681775188067\n",
    "Random Forest MSE: 69.77633448275861\n",
    "MLP Regressor MSE: 64.54510624008212\n",
    "XGBoost MSE: 73.98760806174032\n",
    "\n",
    "--------RPCA Num & Bin--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003335061983338765\n",
    "Cleaned dataset shape: (1301, 1749)\n",
    "Linear Regression MSE: 1.5921342189492617e+28\n",
    "Random Forest MSE: 76.84507739463601\n",
    "MLP Regressor MSE: 220.2787336807211\n",
    "XGBoost MSE: 74.42477144102078\n",
    "\n",
    "Dim = 3\n",
    "Scaled: MinMax Scaler\n",
    "Reconstruction MSE: 0.003322121164396924\n",
    "Cleaned dataset shape: (1301, 1749)\n",
    "Linear Regression MSE: 3.435636078812604e+27\n",
    "Random Forest MSE: 68.0639318007663\n",
    "MLP Regressor MSE: 170.48459862383126\n",
    "XGBoost MSE: 66.91970884783616\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b7f5d3eb-16ff-40c8-b434-e6b6359106f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09005376802270713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_transposed = numerical_features.T\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data_transposed)\n",
    "\n",
    "reduced_dim = 512\n",
    "pca = PCA(n_components=reduced_dim, svd_solver='full')\n",
    "pca_reduced = pca.fit_transform(standardized_data)\n",
    "pca_reconstructed = pca.inverse_transform(pca_reduced)\n",
    "\n",
    "mse_pca = mean_squared_error(standardized_data, pca_reconstructed)\n",
    "\n",
    "print(mse_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "844b7905-19dc-4d61-960a-6a2f9e11c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.DataFrame(pca_reduced, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "56579366-2c58-42a4-89ba-efc7380817b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both binary and reduced numerical dataset\n",
    "reduced_df = pd.DataFrame(pca_reduced, index=sample_ids)\n",
    "\n",
    "binary_transposed = binary_features.T \n",
    "# reduced_df.index = reduced_df.index.astype(float)\n",
    "# print(reduced_df.index)\n",
    "# print(binary_transposed.index)\n",
    "# print(\"Do sample names match?\", (reduced_df.index == binary_transposed.index).all())\n",
    "combined_df = pd.concat([reduced_df, binary_transposed], axis=1)\n",
    "combined_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = combined_df.join(metadata_df[['host_age']], how='inner')\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# # Original dataset shape: (1312, 1749)\n",
    "# # Cleaned dataset shape: (1301, 1749)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "79d15b9d-2d84-49e0-b886-e00517a9d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 2841.559584303109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "39eeaee6-6905-4886-b637-e6cf45dde8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 66.89663639846744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0f93ad2a-89d5-4fe6-9cc6-0427c5b0d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor MSE: 895.1086733724248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5bba6f61-48e8-4256-91d0-5c2200489221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 70.36381670902817\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9307088-2a94-4aa0-9c4c-d1b5096176af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------RPCA Num ONLY--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003335061983338765\n",
    "Cleaned dataset shape: (1301, 4)\n",
    "Linear Regression MSE: 68.21386741357641\n",
    "Random Forest MSE: 74.40174406130268\n",
    "MLP Regressor MSE: 68.23618351926648\n",
    "XGBoost MSE: 73.97999390869334\n",
    "\n",
    "Dim = 10\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.0033221211643852722\n",
    "Linear Regression MSE: 64.54681775188067\n",
    "Random Forest MSE: 69.77633448275861\n",
    "MLP Regressor MSE: 64.54510624008212\n",
    "XGBoost MSE: 73.98760806174032\n",
    "\n",
    "--------RPCA Num & Bin--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003335061983338765\n",
    "Cleaned dataset shape: (1301, 1749)\n",
    "Linear Regression MSE: 1.5921342189492617e+28\n",
    "Random Forest MSE: 76.84507739463601\n",
    "MLP Regressor MSE: 220.2787336807211\n",
    "XGBoost MSE: 74.42477144102078\n",
    "\n",
    "Dim = 3\n",
    "Scaled: MinMax Scaler\n",
    "Reconstruction MSE: 0.003322121164396924\n",
    "Cleaned dataset shape: (1301, 1749)\n",
    "Linear Regression MSE: 3.435636078812604e+27\n",
    "Random Forest MSE: 68.0639318007663\n",
    "MLP Regressor MSE: 170.48459862383126\n",
    "XGBoost MSE: 66.91970884783616\n",
    "'''\n",
    "\n",
    "'''\n",
    "--------PCA--------\n",
    "Dim = 128\n",
    "Reconstruction MSE(full): 0.3550807607177242\n",
    "Cleaned dataset shape: (1301, 129)\n",
    "Linear Regression MSE: 331.4252737672184\n",
    "Random Forest MSE: 65.77763601532565\n",
    "MLP Regressor MSE: 1105.2147394644705\n",
    "XGBoost MSE: 71.20844263899042\n",
    "Reconstruction MSE(auto): 0.355807160249656\n",
    "Linear Regression MSE: 285.86977878343504\n",
    "Random Forest MSE: 67.39131762452108\n",
    "MLP Regressor MSE: 1057.784862529724\n",
    "XGBoost MSE: 72.47198869159442\n",
    "\n",
    "Dim = 512\n",
    "Reconstruction MSE(full): 0.09005376802270713\n",
    "Linear Regression MSE: 2841.559584303109\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 895.1086733724248\n",
    "XGBoost MSE: 70.36381670902817\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "--------PCA With Both--------\n",
    "Dim = 512\n",
    "PCA MSE: 0.09005376802270713\n",
    "Cleaned dataset shape: (1301, 2258)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "04eadbfa-c3b0-42bd-a315-27fd95d30794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "21.0\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df['host_age'].max())\n",
    "print(cleaned_df['host_age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59cc7c-4c26-49e6-9f0f-cbaebc9641de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5b2014-736d-4d76-a522-bb6ced4d117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "from biom import Table\n",
    "from gemelli.rpca import rpca\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f63545-89e5-4386-ab13-5175f3f05c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27cef36-9922-48c7-b414-fd5448b90e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = './adrc_full_metadata.csv'\n",
    "meta = pd.read_csv(meta_path)\n",
    "\n",
    "metab1_path = './../v2_dataset/metab_df_1_processed.csv'\n",
    "metab2_path = './../v2_dataset/metab_df_2_processed.csv'\n",
    "metab3_path = './../v2_dataset/metab_drugs_df_1_processed.csv'\n",
    "metab4_path = './../v2_dataset/metab_drugs_df_2_processed.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e473b463-7b0d-4324-9508-4813cfcf7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# print(df.head(5))\n",
    "\n",
    "# print(df2.shape)\n",
    "# print(df2.head(5))\n",
    "\n",
    "# print(df3.shape)\n",
    "# print(df3.head(5))\n",
    "\n",
    "# print(df4.shape)\n",
    "# print(df4.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c271a63-f326-4e67-86dc-dd4fe0514952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "        \n",
    "        \n",
    "def rpca_fr(path, dim):\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "\n",
    "    df['feature_type'] = df.apply(classify_feature, axis=1)\n",
    "    binary_features = df[df['feature_type'] == 'binary']\n",
    "    numerical_features = df[df['feature_type'] == 'numerical']\n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    print(f'Number of binary features: {binary_features.shape[0]}')\n",
    "    print(f'Number of numerical features: {numerical_features.shape[0]}')\n",
    "\n",
    "    scaled = numerical_features.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.index.tolist()  # Sample IDs (rows)\n",
    "    feature_ids = numerical_features.columns.tolist()   # Feature IDs (columns)\n",
    "    table_scaled = Table(scaled.T, feature_ids, sample_ids)\n",
    "\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled, X_reconstructed)\n",
    "    print(f'Reconstruction MSE: {mse}')\n",
    "    \n",
    "    print(f'Sample scores shape: {sample_scores.shape}')\n",
    "    print(f'Feature scores shape: {feature_scores.shape}')\n",
    "    print(f'Original scaled data shape: {scaled.T.shape}')\n",
    "    print(f'Reconstructed data shape: {X_reconstructed.shape}\\n')\n",
    "\n",
    "    reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ad263c-fc20-47f4-a22b-cb6b76ad98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_fr(path, dim, svd='full'):\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "\n",
    "    df['feature_type'] = df.apply(classify_feature, axis=1)\n",
    "    binary_features = df[df['feature_type'] == 'binary']\n",
    "    numerical_features = df[df['feature_type'] == 'numerical']\n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    print(f'Number of binary features: {binary_features.shape[0]}')\n",
    "    print(f'Number of numerical features: {numerical_features.shape[0]}')\n",
    "\n",
    "    scaled = numerical_features.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "    pca = PCA(n_components=dim, svd_solver=svd)\n",
    "    reduced_df = pca.fit_transform(scaled)\n",
    "    X_reconstructed = pca.inverse_transform(reduced_df)\n",
    "    \n",
    "    mse = mean_squared_error(scaled, X_reconstructed)\n",
    "    print(f'Reconstruction MSE: {mse}')\n",
    "    \n",
    "    print(f'Reduced data shape: {reduced_df.shape}')    \n",
    "    print(f'Original scaled data shape: {scaled.shape}')\n",
    "    print(f'Reconstructed data shape: {X_reconstructed.shape}\\n')\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c4501a-eff5-4646-81b5-3b5fe0c8e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1, df2):\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c600d22a-a9c5-400f-870e-bd24015d5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(reduced, y):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna(subset=['apoe4_binary'])\n",
    "    X = cleaned_df.drop(columns=['apoe4_binary'])\n",
    "    y = cleaned_df['apoe4_binary']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497f2065-c744-4f6a-a9b7-6d697811a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, Y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_model = LogisticRegression(random_state=42)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
    "    print(f\"Classification Report for Logistic Regression:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
    "    print(f\"Classification Report for Random Forest:\\n{classification_report(y_test, y_pred_rf)}\")\n",
    "\n",
    "    # MLP Classifier (Neural Network)\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=4000, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    print(f\"MLP Classifier Accuracy: {accuracy_mlp}\")\n",
    "    print(f\"Classification Report for MLP Classifier:\\n{classification_report(y_test, y_pred_mlp)}\")\n",
    "\n",
    "    # XGBoost Classifier\n",
    "    xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n",
    "    print(f\"Classification Report for XGBoost:\\n{classification_report(y_test, y_pred_xgb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4dea284-3946-4e8e-b73e-40a8ec374cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_age_1 = meta['host_age'][:611]\n",
    "# host_age_2 = meta['host_age'][611:]\n",
    "# print(meta.head)\n",
    "apoe4_1 = meta['apoe4'][:611]\n",
    "binary_data_1 = apoe4_1.map({'Carrier': 1, 'Non-carrier': 0})\n",
    "apoe4_1 = pd.DataFrame({'apoe4_binary': binary_data_1})\n",
    "\n",
    "apoe4_2 = meta['apoe4'][611:]\n",
    "binary_data_2 = apoe4_2.map({'Carrier': 1, 'Non-carrier': 0})\n",
    "apoe4_2 = pd.DataFrame({'apoe4_binary': binary_data_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdb201-1fb4-4a23-9b09-eb564df1c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = apoe4_1.value_counts()\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d584596-54fa-4255-80b0-621cf2a29c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = apoe4_2.value_counts()\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e57276c-b2a3-43b8-b464-b101d091cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(path, bi_path, rpca_dim, pca_dim, y, svd='full'):\n",
    "    print(f'--------RPCA Results--------')\n",
    "    rpca_df = rpca_fr(path, rpca_dim)\n",
    "\n",
    "    # print(f'For Numerical Dataset Only')\n",
    "    # X_rpca_nu, Y_rpca_nu = get_X_y(rpca_df, y)\n",
    "    # training(X_rpca_nu, Y_rpca_nu)\n",
    "    \n",
    "    print(f'For Both Numerical And Binary Dataset')\n",
    "    df = pd.read_csv(bi_path, delimiter='\\t')\n",
    "    bi = df.astype(int)\n",
    "    combined_rpca = combine_df(rpca_df, bi)\n",
    "    X_rpca, Y_rpca = get_X_y(combined_rpca, y)\n",
    "    training(X_rpca, Y_rpca)\n",
    "\n",
    "    print(f'--------PCA Results--------')\n",
    "    pca_df = pca_fr(path, pca_dim, svd)\n",
    "    \n",
    "    # print(f'For Numerical Dataset Only')\n",
    "    # X_pca_nu, Y_pca_nu = get_X_y(pca_df, y)\n",
    "    # training(X_pca_nu, Y_pca_nu)\n",
    "    \n",
    "    print(f'For Both Numerical And Binary Dataset')\n",
    "    df = pd.read_csv(bi_path, delimiter='\\t')\n",
    "    bi = df.astype(int)\n",
    "    # pca_df = pd.DataFrame(pca_df)\n",
    "    combined_pca = combine_df(pca_df, bi)\n",
    "    X_pca, Y_pca = get_X_y(combined_pca, y)\n",
    "    X_pca.columns = X_pca.columns.astype(str)\n",
    "    training(X_pca, Y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4f0a63-a7ed-4c73-98e3-0624bd8c7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------RPCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 611\n",
      "Reconstruction MSE: 0.01250146068203957\n",
      "Sample scores shape: (611, 3)\n",
      "Feature scores shape: (20628, 3)\n",
      "Original scaled data shape: (20628, 611)\n",
      "Reconstructed data shape: (611, 20628)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.5306122448979592\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.74      0.63        54\n",
      "         1.0       0.46      0.27      0.34        44\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.51      0.51      0.49        98\n",
      "weighted avg       0.51      0.53      0.50        98\n",
      "\n",
      "Random Forest Accuracy: 0.5612244897959183\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.91      0.70        54\n",
      "         1.0       0.55      0.14      0.22        44\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.55      0.52      0.46        98\n",
      "weighted avg       0.56      0.56      0.48        98\n",
      "\n",
      "MLP Classifier Accuracy: 0.5102040816326531\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.74      0.62        54\n",
      "         1.0       0.42      0.23      0.29        44\n",
      "\n",
      "    accuracy                           0.51        98\n",
      "   macro avg       0.48      0.48      0.46        98\n",
      "weighted avg       0.48      0.51      0.48        98\n",
      "\n",
      "XGBoost Accuracy: 0.4897959183673469\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.70      0.60        54\n",
      "         1.0       0.38      0.23      0.29        44\n",
      "\n",
      "    accuracy                           0.49        98\n",
      "   macro avg       0.46      0.47      0.44        98\n",
      "weighted avg       0.46      0.49      0.46        98\n",
      "\n",
      "--------PCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 611\n",
      "Reconstruction MSE: 0.30418474524385936\n",
      "Reduced data shape: (611, 128)\n",
      "Original scaled data shape: (611, 20628)\n",
      "Reconstructed data shape: (611, 20628)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.47959183673469385\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.61      0.56        54\n",
      "         1.0       0.40      0.32      0.35        44\n",
      "\n",
      "    accuracy                           0.48        98\n",
      "   macro avg       0.46      0.46      0.46        98\n",
      "weighted avg       0.47      0.48      0.47        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5510204081632653\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.80      0.66        54\n",
      "         1.0       0.50      0.25      0.33        44\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.53      0.52      0.50        98\n",
      "weighted avg       0.54      0.55      0.51        98\n",
      "\n",
      "MLP Classifier Accuracy: 0.5306122448979592\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.70      0.62        54\n",
      "         1.0       0.47      0.32      0.38        44\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.51      0.51      0.50        98\n",
      "weighted avg       0.52      0.53      0.51        98\n",
      "\n",
      "XGBoost Accuracy: 0.5816326530612245\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.89      0.70        54\n",
      "         1.0       0.60      0.20      0.31        44\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.59      0.55      0.50        98\n",
      "weighted avg       0.59      0.58      0.52        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 3\n",
    "# PCA Dim = 128\n",
    "get_result(metab1_path, metab3_path, 3, 128, apoe4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fe949-1a66-42bb-a752-eeb1550fc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 10\n",
    "# PCA Dim = 256\n",
    "get_result(metab1_path, metab3_path, 10, 256, apoe4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfeffe8-fe48-49d4-b22b-907107dfe4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------RPCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 611\n",
      "Reconstruction MSE: 0.012462772977431187\n",
      "Sample scores shape: (611, 16)\n",
      "Feature scores shape: (20628, 16)\n",
      "Original scaled data shape: (20628, 611)\n",
      "Reconstructed data shape: (611, 20628)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.5306122448979592\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.74      0.63        54\n",
      "         1.0       0.46      0.27      0.34        44\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.51      0.51      0.49        98\n",
      "weighted avg       0.51      0.53      0.50        98\n",
      "\n",
      "Random Forest Accuracy: 0.5510204081632653\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.93      0.69        54\n",
      "         1.0       0.50      0.09      0.15        44\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.53      0.51      0.42        98\n",
      "weighted avg       0.53      0.55      0.45        98\n",
      "\n",
      "MLP Classifier Accuracy: 0.5510204081632653\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.76      0.65        54\n",
      "         1.0       0.50      0.30      0.37        44\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.53      0.53      0.51        98\n",
      "weighted avg       0.54      0.55      0.53        98\n",
      "\n",
      "XGBoost Accuracy: 0.5408163265306123\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.70      0.63        54\n",
      "         1.0       0.48      0.34      0.40        44\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.53      0.52      0.51        98\n",
      "weighted avg       0.53      0.54      0.53        98\n",
      "\n",
      "--------PCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 611\n",
      "Reconstruction MSE: 0.012952282020246434\n",
      "Reduced data shape: (611, 512)\n",
      "Original scaled data shape: (611, 20628)\n",
      "Reconstructed data shape: (611, 20628)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.46938775510204084\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.46      0.49        54\n",
      "         1.0       0.42      0.48      0.45        44\n",
      "\n",
      "    accuracy                           0.47        98\n",
      "   macro avg       0.47      0.47      0.47        98\n",
      "weighted avg       0.48      0.47      0.47        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5714285714285714\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.98      0.72        54\n",
      "         1.0       0.75      0.07      0.12        44\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.66      0.52      0.42        98\n",
      "weighted avg       0.65      0.57      0.45        98\n",
      "\n",
      "MLP Classifier Accuracy: 0.5\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.59      0.57        54\n",
      "         1.0       0.44      0.39      0.41        44\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.49      0.49      0.49        98\n",
      "weighted avg       0.49      0.50      0.50        98\n",
      "\n",
      "XGBoost Accuracy: 0.5408163265306123\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.89      0.68        54\n",
      "         1.0       0.45      0.11      0.18        44\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.50      0.50      0.43        98\n",
      "weighted avg       0.51      0.54      0.46        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 16\n",
    "# PCA Dim = 512\n",
    "get_result(metab1_path, metab3_path, 16, 512, apoe4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d93e863-feff-4b42-afd7-43065cf2ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------RPCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 701\n",
      "Reconstruction MSE: 0.009809758083284662\n",
      "Sample scores shape: (701, 3)\n",
      "Feature scores shape: (17354, 3)\n",
      "Original scaled data shape: (17354, 701)\n",
      "Reconstructed data shape: (701, 17354)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.5714285714285714\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.92      0.72        74\n",
      "         1.0       0.40      0.08      0.13        52\n",
      "\n",
      "    accuracy                           0.57       126\n",
      "   macro avg       0.49      0.50      0.42       126\n",
      "weighted avg       0.51      0.57      0.47       126\n",
      "\n",
      "Random Forest Accuracy: 0.5952380952380952\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        74\n",
      "         1.0       0.55      0.12      0.19        52\n",
      "\n",
      "    accuracy                           0.60       126\n",
      "   macro avg       0.57      0.52      0.46       126\n",
      "weighted avg       0.58      0.60      0.51       126\n",
      "\n",
      "MLP Classifier Accuracy: 0.6031746031746031\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.81      0.71        74\n",
      "         1.0       0.53      0.31      0.39        52\n",
      "\n",
      "    accuracy                           0.60       126\n",
      "   macro avg       0.58      0.56      0.55       126\n",
      "weighted avg       0.59      0.60      0.58       126\n",
      "\n",
      "XGBoost Accuracy: 0.5317460317460317\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.77      0.66        74\n",
      "         1.0       0.37      0.19      0.25        52\n",
      "\n",
      "    accuracy                           0.53       126\n",
      "   macro avg       0.47      0.48      0.46       126\n",
      "weighted avg       0.49      0.53      0.49       126\n",
      "\n",
      "--------PCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 701\n",
      "Reconstruction MSE: 0.44225927060364\n",
      "Reduced data shape: (701, 128)\n",
      "Original scaled data shape: (701, 17354)\n",
      "Reconstructed data shape: (701, 17354)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.4603174603174603\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.51      0.53        74\n",
      "         1.0       0.36      0.38      0.37        52\n",
      "\n",
      "    accuracy                           0.46       126\n",
      "   macro avg       0.45      0.45      0.45       126\n",
      "weighted avg       0.47      0.46      0.46       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5634920634920635\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.92      0.71        74\n",
      "         1.0       0.33      0.06      0.10        52\n",
      "\n",
      "    accuracy                           0.56       126\n",
      "   macro avg       0.46      0.49      0.41       126\n",
      "weighted avg       0.48      0.56      0.46       126\n",
      "\n",
      "MLP Classifier Accuracy: 0.5396825396825397\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.69      0.64        74\n",
      "         1.0       0.42      0.33      0.37        52\n",
      "\n",
      "    accuracy                           0.54       126\n",
      "   macro avg       0.51      0.51      0.50       126\n",
      "weighted avg       0.52      0.54      0.53       126\n",
      "\n",
      "XGBoost Accuracy: 0.5714285714285714\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.80      0.69        74\n",
      "         1.0       0.46      0.25      0.33        52\n",
      "\n",
      "    accuracy                           0.57       126\n",
      "   macro avg       0.53      0.52      0.51       126\n",
      "weighted avg       0.55      0.57      0.54       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 3\n",
    "# PCA Dim = 128\n",
    "get_result(metab2_path, metab4_path, 3, 128, apoe4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6c37-c3ee-447f-b6e3-30eb59eb061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 10\n",
    "# PCA Dim = 256\n",
    "get_result(metab2_path, metab4_path, 10, 256, apoe4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff932dd-b4da-49cf-bda4-b11f3ddd115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------RPCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 701\n",
      "Reconstruction MSE: 0.009772766867363093\n",
      "Sample scores shape: (701, 16)\n",
      "Feature scores shape: (17354, 16)\n",
      "Original scaled data shape: (17354, 701)\n",
      "Reconstructed data shape: (701, 17354)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.5793650793650794\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.93      0.72        74\n",
      "         1.0       0.44      0.08      0.13        52\n",
      "\n",
      "    accuracy                           0.58       126\n",
      "   macro avg       0.52      0.50      0.43       126\n",
      "weighted avg       0.53      0.58      0.48       126\n",
      "\n",
      "Random Forest Accuracy: 0.5634920634920635\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.93      0.72        74\n",
      "         1.0       0.29      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.56       126\n",
      "   macro avg       0.43      0.49      0.39       126\n",
      "weighted avg       0.46      0.56      0.45       126\n",
      "\n",
      "MLP Classifier Accuracy: 0.626984126984127\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.82      0.72        74\n",
      "         1.0       0.58      0.35      0.43        52\n",
      "\n",
      "    accuracy                           0.63       126\n",
      "   macro avg       0.61      0.59      0.58       126\n",
      "weighted avg       0.62      0.63      0.60       126\n",
      "\n",
      "XGBoost Accuracy: 0.5793650793650794\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.81      0.69        74\n",
      "         1.0       0.48      0.25      0.33        52\n",
      "\n",
      "    accuracy                           0.58       126\n",
      "   macro avg       0.54      0.53      0.51       126\n",
      "weighted avg       0.55      0.58      0.54       126\n",
      "\n",
      "--------PCA Results--------\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 701\n",
      "Reconstruction MSE: 0.04765471512575212\n",
      "Reduced data shape: (701, 512)\n",
      "Original scaled data shape: (701, 17354)\n",
      "Reconstructed data shape: (701, 17354)\n",
      "\n",
      "For Both Numerical And Binary Dataset\n",
      "Logistic Regression Accuracy: 0.5158730158730159\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.51      0.55        74\n",
      "         1.0       0.43      0.52      0.47        52\n",
      "\n",
      "    accuracy                           0.52       126\n",
      "   macro avg       0.52      0.52      0.51       126\n",
      "weighted avg       0.53      0.52      0.52       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5873015873015873\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.97      0.73        74\n",
      "         1.0       0.50      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.59       126\n",
      "   macro avg       0.55      0.51      0.40       126\n",
      "weighted avg       0.55      0.59      0.46       126\n",
      "\n",
      "MLP Classifier Accuracy: 0.49206349206349204\n",
      "Classification Report for MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.58      0.57        74\n",
      "         1.0       0.38      0.37      0.37        52\n",
      "\n",
      "    accuracy                           0.49       126\n",
      "   macro avg       0.47      0.47      0.47       126\n",
      "weighted avg       0.49      0.49      0.49       126\n",
      "\n",
      "XGBoost Accuracy: 0.5555555555555556\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.86      0.70        74\n",
      "         1.0       0.38      0.12      0.18        52\n",
      "\n",
      "    accuracy                           0.56       126\n",
      "   macro avg       0.48      0.49      0.44       126\n",
      "weighted avg       0.50      0.56      0.48       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 16\n",
    "# PCA Dim = 512\n",
    "get_result(metab2_path, metab4_path, 16, 512, apoe4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2c1c1-e681-4757-9ec8-792603ac5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

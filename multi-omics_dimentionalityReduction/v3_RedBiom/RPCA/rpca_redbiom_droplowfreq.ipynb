{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47f2616-6dc7-455d-aad3-88bac044d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from biom import Table\n",
    "from gemelli.rpca import rpca\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b85fd4-d8db-4b43-bfe1-26e23a2d4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f874e247-64c9-4e1c-9fe1-85451bbb0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = \"./redbiom_adrc_wolr2_fecal_v2.biom\"\n",
    "meta_path = \"./redbiom_adrc_wolr2_fecal_v2.tsv\"\n",
    "\n",
    "table = biom.load_table(table_path)\n",
    "\n",
    "meta = pd.read_csv(meta_path, sep='\\t')\n",
    "\n",
    "# print(meta.shape)\n",
    "# print(meta.head(5))\n",
    "# print(f\"Table shape: {table.shape}\")\n",
    "# print(table.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3250c2f4-4c0e-45ec-944d-4e809cc33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BIOM table to a pandas DataFrame (OTUs as rows, samples as columns)\n",
    "biom_df = pd.DataFrame(table.matrix_data.toarray(), index=table.ids(axis='observation'), columns=table.ids(axis='sample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0d9dbb5-ccc8-4dbc-b39a-27bfca5a0265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15363, 13436)\n",
      "(13436, 15363)\n"
     ]
    }
   ],
   "source": [
    "biom_df_T = biom_df.T\n",
    "print(biom_df.shape)\n",
    "print(biom_df_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58c69bb6-98b0-4024-942d-98c7b909ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frequency = 20\n",
    "columns_to_drop = biom_df_T.columns[biom_df_T.sum() < feature_frequency] #drop columns with low prev\n",
    "df1 = biom_df_T.drop(columns = columns_to_drop)\n",
    "# df1 = utils.clr_transformation(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb1f33c5-a7b1-4396-832f-c1fd3ca3a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13436, 8308)\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d090da6-9630-4ef0-9129-f35e0f40b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "def split_features(df):\n",
    "    df['feature_type'] = df.apply(classify_feature, axis=1)\n",
    "\n",
    "    binary_features = df[df['feature_type'] == 'binary']\n",
    "    numerical_features = df[df['feature_type'] == 'numerical']\n",
    "    \n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    \n",
    "    print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "    print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n",
    "\n",
    "    return binary_features, numerical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175275bb-705c-46a2-8915-d65f7441ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e048d-3a84-4642-9f23-608aa7775f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bc988-7d58-4519-8939-fef3766a4e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3daa3-2006-4e76-880c-e08cb12a4b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875c4b4-2c98-4af5-8fde-1511a5a475ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f51ef8ee-1de3-4636-8b7e-cb6d1e073bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clr_transformation(df):\n",
    "    # Replace zeros with a very small number to avoid issues with log(0)\n",
    "    df_replaced_zeros = df.replace(0, 1e-6)\n",
    "    \n",
    "    # Calculate the geometric mean for each row\n",
    "    geometric_mean = df_replaced_zeros.apply(lambda x: np.exp(np.mean(np.log(x))), axis=1)\n",
    "    \n",
    "    # Apply the CLR transformation\n",
    "    clr_transformed = df_replaced_zeros.apply(lambda x: np.log(x / geometric_mean[x.name]), axis=1)\n",
    "    \n",
    "    return clr_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a179e07-837b-4ddd-87ce-f4f561813a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Original Dataset Feature Info---\n",
      "Number of binary features: 0\n",
      "Number of numerical features: 15363\n",
      "--------Dataset Feature Info With Feature Frequency = 20--------\n",
      "Number of binary features: 51\n",
      "Number of numerical features: 8257\n"
     ]
    }
   ],
   "source": [
    "df1_clr = clr_transformation(df1)\n",
    "\n",
    "print(f'--------Original Dataset Feature Info---')\n",
    "biom_bin, biom_num = split_features(biom_df)\n",
    "print(f'--------Dataset Feature Info With Feature Frequency = {feature_frequency}--------')\n",
    "df1_bin, df1_num = split_features(df1.T)\n",
    "# print(f'--------Dataset Feature Info After Clr Transformation--------')\n",
    "# df1_clr_bin, df1_clr_num = split_features(df1.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9361d947-cce6-408b-8c13-9fd008aa1173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOriginal Binary: 1568/(1568+13795) = 10.2%\\n\\n----FF=5----\\nAfter Dropping Binary: 3.5%\\n----FF=6----\\nAfter Dropping Binary: 270/(270+9294) = 2.8%\\n----FF=10----\\nAfter Dropping Binary: 130/(130+8919) = 1.4%\\n----FF=15----\\nAfter Dropping Binary: 83/(83+8555) = 0.96%\\n----FF=20----\\nAfter Dropping Binary: 51/(51+8257) = 0.61%\\n\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Original Binary: 1568/(1568+13795) = 10.2%\n",
    "\n",
    "----FF=5----\n",
    "After Dropping Binary: 3.5%\n",
    "----FF=6----\n",
    "After Dropping Binary: 270/(270+9294) = 2.8%\n",
    "----FF=10----\n",
    "After Dropping Binary: 130/(130+8919) = 1.4%\n",
    "----FF=15----\n",
    "After Dropping Binary: 83/(83+8555) = 0.96%\n",
    "----FF=20----\n",
    "After Dropping Binary: 51/(51+8257) = 0.61%\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86556f20-b2cf-4160-adb9-c6e2c8a56dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = df1_num.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[df1_num.columns] = scaler.fit_transform(df1_num)\n",
    "scaled = scaler.fit_transform(df1_num)\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled.shape) # (13795, 13436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "914ea2a2-4b9a-4b51-bc9d-00db0da6656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df1_num.head(5))\n",
    "# # print(df1.T.head(5))\n",
    "# print(df1.shape)\n",
    "# print(scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59f488b7-5606-4309-b7b4-68738dc386dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_fr(scaled, numerical_features, dim):\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "    feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "    table_scaled = Table(scaled, feature_ids, sample_ids)\n",
    "\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "    print(f\"Reconstruction MSE: {mse}\")\n",
    "    \n",
    "    print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "    print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "    print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "    print(f\"Reconstructed data shape: {X_reconstructed.shape}\")\n",
    "\n",
    "    return sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a11b5bf-3f6d-4d3e-a9db-3a327dad28c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727725965.8551793\n",
      "Reconstruction MSE: 0.0003722700606232105\n",
      "Sample scores shape: (13436, 4)\n",
      "Feature scores shape: (8257, 4)\n",
      "Original scaled data shape: (13436, 8257)\n",
      "Reconstructed data shape: (13436, 8257)\n",
      "Execution time: 323.2673773765564 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "reduced_data = rpca_fr(scaled, df1_num, 4)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dde79c9c-af59-4250-84a5-0b1766e242d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1, df2):\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return pd.concat([df1, df2], axis=1)\n",
    "    \n",
    "def get_X_y(reduced, y, cat):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna()\n",
    "    X = cleaned_df.drop(columns=[cat])\n",
    "    y = cleaned_df[cat]\n",
    "    return X, y\n",
    "\n",
    "def training(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # # MLP\n",
    "    # mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=5000, random_state=42)\n",
    "    # mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    # y_pred_mlp = mlp_model.predict(X_test)\n",
    "    # mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    # print(f\"MLP Regressor MSE: {mse_mlp}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c8df780-5ec3-4231-938a-7c88524391be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'host_age'\n",
    "cat_y = meta[cat]\n",
    "cat_X = combine_df(reduced_data, df1_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc5c99d1-db7f-4408-bf17-99a49acaf95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 194.21174991381397\n",
      "Random Forest MSE: 158.43241928386362\n",
      "XGBoost MSE: 225.44448023642371\n"
     ]
    }
   ],
   "source": [
    "X, y = get_X_y(cat_X, cat_y, cat)\n",
    "training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b668ea23-b4ab-46b9-a46c-ffd38e5aadb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.76\n",
      "8.38\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dim = 3\n",
    "Linear Regression MSE: 3.995264211009359e+28\n",
    "Random Forest MSE: 332.3066680347287\n",
    "/opt/conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
    "  warnings.warn(\"Training interrupted by user.\")\n",
    "MLP Regressor MSE: 685.7311446346571\n",
    "XGBoost MSE: 299.14464191813653\n",
    "\n",
    "Dim = 16\n",
    "Reconstruction MSE: 0.00022048968863458537\n",
    "Sample scores shape: (13436, 16)\n",
    "Feature scores shape: (13795, 16)\n",
    "Original scaled data shape: (13436, 13795)\n",
    "Reconstructed data shape: (13436, 13795)\n",
    "\n",
    "Linear Regression MSE: 1.1185584052698574e+29\n",
    "Random Forest MSE: 297.4191591508802\n",
    "XGBoost MSE: 306.4656906982071\n",
    "\n",
    "--------Drop Low Feature Frequency--------\n",
    "\n",
    "----Dim = 4----\n",
    "\n",
    "--Feature Freq = 5--\n",
    "1727723260.1230855\n",
    "Reconstruction MSE: 0.0003263223654129197\n",
    "Sample scores shape: (13436, 4)\n",
    "Feature scores shape: (9419, 4)\n",
    "Original scaled data shape: (13436, 9419)\n",
    "Reconstructed data shape: (13436, 9419)\n",
    "Execution time: 364.3079755306244 seconds\n",
    "\n",
    "Linear Regression MSE: 449.6641499171495\n",
    "Random Forest MSE: 285.2861205474667\n",
    "XGBoost MSE: 284.12249716704207\n",
    "\n",
    "--FF=6--\n",
    "1727724124.2568882\n",
    "Reconstruction MSE: 0.000330731990772629\n",
    "Sample scores shape: (13436, 4)\n",
    "Feature scores shape: (9294, 4)\n",
    "Original scaled data shape: (13436, 9294)\n",
    "Reconstructed data shape: (13436, 9294)\n",
    "Execution time: 368.4696533679962 seconds\n",
    "\n",
    "Linear Regression MSE: 837.1834712312027\n",
    "Random Forest MSE: 254.49559979720556\n",
    "XGBoost MSE: 311.0350083620908\n",
    "\n",
    "--FF=10--\n",
    "1727724685.7488904\n",
    "Reconstruction MSE: 0.00034463803042504126\n",
    "Sample scores shape: (13436, 4)\n",
    "Feature scores shape: (8919, 4)\n",
    "Original scaled data shape: (13436, 8919)\n",
    "Reconstructed data shape: (13436, 8919)\n",
    "Execution time: 337.9884605407715 seconds\n",
    "\n",
    "Linear Regression MSE: 251.11581757858377\n",
    "Random Forest MSE: 263.78265246685015\n",
    "XGBoost MSE: 239.09977714115107\n",
    "\n",
    "--FF=15--\n",
    "1727725337.0230546\n",
    "Reconstruction MSE: 0.00035930221102317895\n",
    "Sample scores shape: (13436, 4)\n",
    "Feature scores shape: (8555, 4)\n",
    "Original scaled data shape: (13436, 8555)\n",
    "Reconstructed data shape: (13436, 8555)\n",
    "Execution time: 332.6713442802429 seconds\n",
    "\n",
    "Linear Regression MSE: 157.05134799361545\n",
    "Random Forest MSE: 214.4763377781649\n",
    "XGBoost MSE: 276.81906855632036\n",
    "\n",
    "--FF=20--\n",
    "1727725965.8551793\n",
    "Reconstruction MSE: 0.0003722700606232105\n",
    "Sample scores shape: (13436, 4)\n",
    "Feature scores shape: (8257, 4)\n",
    "Original scaled data shape: (13436, 8257)\n",
    "Reconstructed data shape: (13436, 8257)\n",
    "Execution time: 323.2673773765564 seconds\n",
    "\n",
    "Linear Regression MSE: 194.21174991381397\n",
    "Random Forest MSE: 158.43241928386362\n",
    "XGBoost MSE: 225.44448023642371\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "print(y.max())\n",
    "print(y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9e768-2e1c-496a-9c9e-5eda92437a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = pd.DataFrame(scaler.fit_transform(numerical_features.T).T, index=numerical_features.index, columns=numerical_features.columns)\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ea9de-eee2-46e2-8522-0aecb950e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "def split_feature(biom_df):\n",
    "    biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "    binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "    numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "    \n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    \n",
    "    print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "    print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n",
    "\n",
    "    return binary_features, numerical_features\n",
    "\n",
    "def scale_data(numerical_features):\n",
    "    scaled_d = numerical_features.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "    scaled = scaler.fit_transform(numerical_features.T).T\n",
    "    return scaled\n",
    "\n",
    "def rpca_fr(scaled, numerical_features, dim):\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "    feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "    table_scaled = Table(scaled, feature_ids, sample_ids)\n",
    "\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "    print(f\"Reconstruction MSE: {mse}\")\n",
    "    \n",
    "    print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "    print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "    print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "    print(f\"Reconstructed data shape: {X_reconstructed.shape}\")\n",
    "\n",
    "    return sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787d6e0-f73a-48d8-b09b-97f25d393b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca(df, dim):\n",
    "    bin_data, num_data = split_feature(df)\n",
    "    scaled_data = scale_data(num_data)\n",
    "    reduced_data = rpca_fr(scaled_data, num_data, dim)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e87dca-d012-4160-bf20-4496d9b828ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpca(biom_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadded7-32e8-477e-87c1-30b8afdf82f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d470e-ff1e-43ae-9df4-409bd005176a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d8688-0ad3-41fb-8d7b-5cf7bd04a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += 1e-10\n",
    "sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "table_scaled = Table(scaled, feature_ids, sample_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5008b3f-1a82-499c-897f-5c8726ff1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3  # Number of components to reduce to\n",
    "rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "ordination, distance = rpca_results\n",
    "sample_scores = ordination.samples  # Scores for samples\n",
    "feature_scores = ordination.features  # Scores for features\n",
    "\n",
    "X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "\n",
    "mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "print(f\"Reconstruction MSE: {mse}\")\n",
    "\n",
    "print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "print(f\"Reconstructed data shape: {X_reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81136b2e-6364-43c8-a7df-35f846aed677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction MSE: 0.003958728646643008\n",
    "# Sample scores shape: (1312, 3)\n",
    "# Feature scores shape: (1102, 3)\n",
    "# Original scaled data shape: (1312, 1102)\n",
    "# Reconstructed data shape: (1312, 1102)\n",
    "\n",
    "\n",
    "# Reconstruction MSE: 0.0033221211643852722\n",
    "# Sample scores shape: (1312, 10)\n",
    "# Feature scores shape: (8448, 10)\n",
    "# Original scaled data shape: (1312, 8448)\n",
    "# Reconstructed data shape: (1312, 8448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafb11d-9636-4cad-873c-8ba30e505315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordination)\n",
    "print(distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752e67b-ff23-40b1-9fa8-62f8a772c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using reduced scaled numerical dataset\n",
    "reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b440b0b-3220-46de-a482-d523b1aaf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using both binary and reduced numerical dataset\n",
    "# reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "\n",
    "# binary_transposed = binary_features.T \n",
    "# # reduced_df.index = reduced_df.index.astype(float)\n",
    "# # print(reduced_df.index)\n",
    "# # print(binary_transposed.index)\n",
    "# # print(\"Do sample names match?\", (reduced_df.index == binary_transposed.index).all())\n",
    "# combined_df = pd.concat([reduced_df, binary_transposed], axis=1)\n",
    "# combined_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "# meta_df = meta.set_index('sample_name')\n",
    "\n",
    "# merged_df = combined_df.join(metadata_df[['host_age']], how='inner')\n",
    "# cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# # print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# # print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# # # Original dataset shape: (1312, 1749)\n",
    "# # # Cleaned dataset shape: (1301, 1749)\n",
    "\n",
    "# X = cleaned_df.drop(columns=['host_age'])\n",
    "# Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca04a73-b8b8-4341-8fc0-24202551e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b456ac-8a26-4758-9630-5771d95ad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a56e40-9e53-4884-91da-daccc97c87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5167e-1752-4aa4-b239-474421634e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94412bce-5232-4b50-9506-fc81cd05d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------RPCA Num ONLY--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003958728646643008\n",
    "Cleaned dataset shape: (1301, 4)\n",
    "Linear Regression MSE: 68.19986181183467\n",
    "Random Forest MSE: 75.95139961685823\n",
    "MLP Regressor MSE: 68.22414791217268\n",
    "XGBoost MSE: 76.82236484129864\n",
    "\n",
    "Dim = 10\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003946154448124425\n",
    "Linear Regression MSE: 59.808153281084984\n",
    "Random Forest MSE: 62.939483908045986\n",
    "MLP Regressor MSE: 59.78929765458566\n",
    "XGBoost MSE: 64.94144790232647\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5d3eb-16ff-40c8-b434-e6b6359106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_transposed = numerical_features.T\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data_transposed)\n",
    "\n",
    "reduced_dim = 512\n",
    "pca = PCA(n_components=reduced_dim, svd_solver='auto')\n",
    "pca_reduced = pca.fit_transform(standardized_data)\n",
    "pca_reconstructed = pca.inverse_transform(pca_reduced)\n",
    "\n",
    "mse_pca = mean_squared_error(standardized_data, pca_reconstructed)\n",
    "\n",
    "print(mse_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7905-19dc-4d61-960a-6a2f9e11c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.DataFrame(pca_reduced, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d15b9d-2d84-49e0-b886-e00517a9d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eeaee6-6905-4886-b637-e6cf45dde8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93ad2a-89d5-4fe6-9cc6-0427c5b0d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba6f61-48e8-4256-91d0-5c2200489221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9307088-2a94-4aa0-9c4c-d1b5096176af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------PCA--------\n",
    "Dim = 128\n",
    "Reconstruction MSE(full): 0.32280275488908244\n",
    "Cleaned dataset shape: (1301, 129)\n",
    "Linear Regression MSE: 2841.559584303109\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 895.1086733724248\n",
    "XGBoost MSE: 70.36381670902817\n",
    "\n",
    "Reconstruction MSE(auto): 0.32696752866827633\n",
    "Linear Regression MSE: 97.59366339211996\n",
    "Random Forest MSE: 64.57761494252874\n",
    "MLP Regressor MSE: 970.4559274788406\n",
    "XGBoost MSE: 64.4298729789169\n",
    "\n",
    "Dim = 512\n",
    "Reconstruction MSE(full): 0.01719558259971444\n",
    "Linear Regression MSE: 551.90068430994\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 811.2290273839908\n",
    "XGBoost MSE: 69.61207270397696\n",
    "\n",
    "Reconstruction MSE(auto): 0.01743150302309283\n",
    "Linear Regression MSE: 580.8346541828049\n",
    "Random Forest MSE: 63.36988850574713\n",
    "MLP Regressor MSE: 911.1563581922785\n",
    "XGBoost MSE: 67.18452645782199\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eadbfa-c3b0-42bd-a315-27fd95d30794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_df['host_age'].max())\n",
    "print(cleaned_df['host_age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59cc7c-4c26-49e6-9f0f-cbaebc9641de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b2014-736d-4d76-a522-bb6ced4d117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "import zipfile\n",
    "import os\n",
    "from biom import Table\n",
    "from gemelli.rpca import rpca\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f63545-89e5-4386-ab13-5175f3f05c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27cef36-9922-48c7-b414-fd5448b90e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13436, 7)\n",
      "                  #SampleID  qiita_study_id  host_age host_age_units  \\\n",
      "0  12675.FIT076E3CAL.170122           12675     40.00          years   \n",
      "1  12142.820081881.2.159050           12142     77.05          years   \n",
      "2  12142.820036321.4.158997           12142     60.80          years   \n",
      "3  12142.820023241.6.158977           12142     70.49          years   \n",
      "4       11666.G0281R.164064           11666     61.00          years   \n",
      "\n",
      "  host_body_site diagnosis apoe  \n",
      "0   UBERON:feces       NaN  NaN  \n",
      "1   UBERON:feces       NaN  NaN  \n",
      "2   UBERON:feces       NaN  NaN  \n",
      "3   UBERON:feces       NaN  NaN  \n",
      "4   UBERON:feces       NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "meta_path = \"./redbiom_adrc_wolr2_fecal_v2.tsv\"\n",
    "meta = pd.read_csv(meta_path, sep='\\t')\n",
    "\n",
    "print(meta.shape)\n",
    "print(meta.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c3a09a-8698-41e7-ad74-bf54411e7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['redbiom_adrc_wolr2_fecal_v2.tsv', '.ipynb_checkpoints', 'redbiom.ipynb', 'redbiom_adrc_wolr2_fecal_v2.biom', 'redbiom_adrc_wolr2_fecal_v2.biom.zip', '__MACOSX', 'redbiom_pca_cuml.ipynb']\n",
      "Loading .biom file: ./redbiom_adrc_wolr2_fecal_v2.biom\n",
      "            10283.JS.1.14.2015.160409  10283.LS.2.23.2015.159711  \\\n",
      "G000005825                        1.0                        0.0   \n",
      "G000006175                        0.0                        0.0   \n",
      "G000006605                        0.0                        0.0   \n",
      "G000006725                        0.0                        0.0   \n",
      "G000006745                        0.0                        2.0   \n",
      "\n",
      "            11129.NH001.JJK.St.160942  11129.NH002.JJK.St.160942  \\\n",
      "G000005825                        0.0                        0.0   \n",
      "G000006175                        0.0                        0.0   \n",
      "G000006605                        8.0                        1.0   \n",
      "G000006725                        0.0                        0.0   \n",
      "G000006745                        0.0                        0.0   \n",
      "\n",
      "            11129.NH003.JJK.St.160942  11129.NH004.JJK.St.160942  \\\n",
      "G000005825                        0.0                        0.0   \n",
      "G000006175                        0.0                        0.0   \n",
      "G000006605                        1.0                       11.0   \n",
      "G000006725                        0.0                        0.0   \n",
      "G000006745                        0.0                        0.0   \n",
      "\n",
      "            11129.NH005.JJK.St.160942  11129.NH006.JJK.St.160942  \\\n",
      "G000005825                        0.0                        0.0   \n",
      "G000006175                        0.0                        0.0   \n",
      "G000006605                        1.0                        0.0   \n",
      "G000006725                        0.0                        0.0   \n",
      "G000006745                        1.0                        0.0   \n",
      "\n",
      "            11129.NH007.JJK.St.160942  11129.NH008.JJK.St.160942  ...  \\\n",
      "G000005825                        0.0                        0.0  ...   \n",
      "G000006175                        0.0                        0.0  ...   \n",
      "G000006605                        0.0                        3.0  ...   \n",
      "G000006725                        0.0                        0.0  ...   \n",
      "G000006745                        0.0                        0.0  ...   \n",
      "\n",
      "            15448.43049648  15448.43051236  15448.43051259  15448.43051286  \\\n",
      "G000005825             0.0             0.0             0.0             1.0   \n",
      "G000006175             0.0             0.0             0.0             0.0   \n",
      "G000006605             0.0             0.0             0.0             0.0   \n",
      "G000006725             0.0             0.0             0.0             0.0   \n",
      "G000006745             0.0             0.0             0.0             0.0   \n",
      "\n",
      "            15448.43051306  15448.43105150  15448.5823422  15448.5827089  \\\n",
      "G000005825             1.0             0.0            0.0            1.0   \n",
      "G000006175             0.0             0.0            0.0            0.0   \n",
      "G000006605             0.0             0.0            5.0            0.0   \n",
      "G000006725             0.0             0.0            0.0            0.0   \n",
      "G000006745             0.0             0.0            0.0            0.0   \n",
      "\n",
      "            15448.5835163  15448.5946764  \n",
      "G000005825            0.0            0.0  \n",
      "G000006175            0.0            0.0  \n",
      "G000006605            0.0            0.0  \n",
      "G000006725            0.0            0.0  \n",
      "G000006745            0.0            0.0  \n",
      "\n",
      "[5 rows x 13436 columns]\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = './redbiom_adrc_wolr2_fecal_v2.biom.zip'\n",
    "\n",
    "extract_to_path = './' \n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "extracted_files = os.listdir(extract_to_path)\n",
    "print(f\"Extracted files: {extracted_files}\")\n",
    "\n",
    "biom_file = None\n",
    "for file in extracted_files:\n",
    "    if file.endswith('.biom'):\n",
    "        biom_file = os.path.join(extract_to_path, file)\n",
    "        break\n",
    "\n",
    "if biom_file:\n",
    "    print(f\"Loading .biom file: {biom_file}\")\n",
    "    \n",
    "    table = biom.load_table(biom_file)\n",
    "    \n",
    "    biom_df = pd.DataFrame(table.matrix_data.toarray(), \n",
    "                      index=table.ids(axis='observation'), \n",
    "                      columns=table.ids(axis='sample'))\n",
    "    \n",
    "    print(biom_df.head())\n",
    "else:\n",
    "    print(\"No .biom file found in the extracted files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7fc619-b742-43bf-b3ba-01269afe97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biom_df.shape # features, samples(15363, 13436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06dd494-66a5-46f4-8deb-a86b21fb8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of binary features: 1568\n",
      "Number of numerical features: 13795\n"
     ]
    }
   ],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "\n",
    "binary_features = binary_features.drop(columns=['feature_type'])\n",
    "numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "\n",
    "print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39bd609-1791-4f99-af0d-2c2d54ace80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = scaler.fit_transform(numerical_features.T).T\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled.shape) # (13795, 13436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00d03cd-130f-45a6-8b61-960a3e4b850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def rpca_fr(scaled, numerical_features, dim):\n",
    "    start_time = time.time()\n",
    "    print(start_time)\n",
    "    \n",
    "    print(\"Building the table...\")\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "    feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "    table_scaled = Table(scaled, feature_ids, sample_ids)\n",
    "\n",
    "    print(\"Running rpca...\")\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    print(\"Generating results...\")\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "    print(f\"Reconstruction MSE: {mse}\")\n",
    "    \n",
    "    print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "    print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "    print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "    print(f\"Reconstructed data shape: {X_reconstructed.shape}\")\n",
    "\n",
    "    return sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828e1e1-553f-4a7d-8a6f-6a0a75d3fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727551371.1404054\n",
      "Building the table...\n",
      "Running rpca...\n"
     ]
    }
   ],
   "source": [
    "reduced_data = rpca_fr(scaled, numerical_features, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ad9f6-89be-4255-9a9b-50408fdb3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(reduced, y):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna(subset=['host_age'])\n",
    "    X = cleaned_df.drop(columns=['host_age'])\n",
    "    y = cleaned_df['host_age']\n",
    "    return X, y\n",
    "\n",
    "def training(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # MLP\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=5000, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    print(f\"MLP Regressor MSE: {mse_mlp}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013879c5-deb4-4740-9788-8d4af5cacb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'host_age'\n",
    "num_data = numerical_features.T\n",
    "reduced_df = combine_df(reduced_data, binary_features.T)\n",
    "reduced_df.index = num_data.index\n",
    "reduced_df.index.name = '#SampleID'\n",
    "meta_df = meta.set_index('#SampleID')\n",
    "\n",
    "merged_df = pd.merge(reduced_df, meta_df[cat], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "f_cleaned_df = merged_df.dropna()\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "print(cleaned_df.shape)\n",
    "print(f_cleaned_df.shape)\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']\n",
    "training(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c271a63-f326-4e67-86dc-dd4fe0514952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "        \n",
    "        \n",
    "def rpca_fr(path, dim):\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "\n",
    "    df['feature_type'] = df.apply(classify_feature, axis=1)\n",
    "    binary_features = df[df['feature_type'] == 'binary']\n",
    "    numerical_features = df[df['feature_type'] == 'numerical']\n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    print(f'Number of binary features: {binary_features.shape[0]}')\n",
    "    print(f'Number of numerical features: {numerical_features.shape[0]}')\n",
    "\n",
    "    scaled = numerical_features.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.index.tolist()  # Sample IDs (rows)\n",
    "    feature_ids = numerical_features.columns.tolist()   # Feature IDs (columns)\n",
    "    table_scaled = Table(scaled.T, feature_ids, sample_ids)\n",
    "\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled, X_reconstructed)\n",
    "    print(f'Reconstruction MSE: {mse}')\n",
    "    \n",
    "    print(f'Sample scores shape: {sample_scores.shape}')\n",
    "    print(f'Feature scores shape: {feature_scores.shape}')\n",
    "    print(f'Original scaled data shape: {scaled.T.shape}')\n",
    "    print(f'Reconstructed data shape: {X_reconstructed.shape}\\n')\n",
    "\n",
    "    reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad263c-fc20-47f4-a22b-cb6b76ad98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_fr(path, dim, svd='full'):\n",
    "    df = pd.read_csv(path, delimiter='\\t')\n",
    "\n",
    "    df['feature_type'] = df.apply(classify_feature, axis=1)\n",
    "    binary_features = df[df['feature_type'] == 'binary']\n",
    "    numerical_features = df[df['feature_type'] == 'numerical']\n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    print(f'Number of binary features: {binary_features.shape[0]}')\n",
    "    print(f'Number of numerical features: {numerical_features.shape[0]}')\n",
    "\n",
    "    scaled = numerical_features.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "    pca = PCA(n_components=dim, svd_solver=svd)\n",
    "    reduced_df = pca.fit_transform(scaled)\n",
    "    X_reconstructed = pca.inverse_transform(reduced_df)\n",
    "    \n",
    "    mse = mean_squared_error(scaled, X_reconstructed)\n",
    "    print(f'Reconstruction MSE: {mse}')\n",
    "    \n",
    "    print(f'Reduced data shape: {reduced_df.shape}')    \n",
    "    print(f'Original scaled data shape: {scaled.shape}')\n",
    "    print(f'Reconstructed data shape: {X_reconstructed.shape}\\n')\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4501a-eff5-4646-81b5-3b5fe0c8e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1, df2):\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600d22a-a9c5-400f-870e-bd24015d5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(reduced, y):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna(subset=['host_age'])\n",
    "    X = cleaned_df.drop(columns=['host_age'])\n",
    "    y = cleaned_df['host_age']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2065-c744-4f6a-a9b7-6d697811a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # MLP\n",
    "    '''/opt/conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: \n",
    "    ConvergenceWarning: Stochastic Optimizer: \n",
    "    Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
    "    warnings.warn(\n",
    "    '''\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=4000, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "    mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    print(f\"MLP Regressor MSE: {mse_mlp}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dea284-3946-4e8e-b73e-40a8ec374cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_age_1 = meta['host_age'][:611]\n",
    "host_age_2 = meta['host_age'][611:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57276c-b2a3-43b8-b464-b101d091cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(path, bi_path, rpca_dim, pca_dim, y, svd='full'):\n",
    "    print(f'--------RPCA Results--------')\n",
    "    rpca_df = rpca_fr(path, rpca_dim)\n",
    "\n",
    "    print(f'For Numerical Dataset Only')\n",
    "    X_rpca_nu, Y_rpca_nu = get_X_y(rpca_df, y)\n",
    "    training(X_rpca_nu, Y_rpca_nu)\n",
    "    \n",
    "    print(f'For Both Numerical And Binary Dataset')\n",
    "    df = pd.read_csv(bi_path, delimiter='\\t')\n",
    "    bi = df.astype(int)\n",
    "    combined_rpca = combine_df(rpca_df, bi)\n",
    "    X_rpca, Y_rpca = get_X_y(combined_rpca, y)\n",
    "    training(X_rpca, Y_rpca)\n",
    "\n",
    "    print(f'--------PCA Results--------')\n",
    "    pca_df = pca_fr(path, pca_dim, svd)\n",
    "    \n",
    "    print(f'For Numerical Dataset Only')\n",
    "    X_pca_nu, Y_pca_nu = get_X_y(pca_df, y)\n",
    "    training(X_pca_nu, Y_pca_nu)\n",
    "    \n",
    "    print(f'For Both Numerical And Binary Dataset')\n",
    "    df = pd.read_csv(bi_path, delimiter='\\t')\n",
    "    bi = df.astype(int)\n",
    "    # pca_df = pd.DataFrame(pca_df)\n",
    "    combined_pca = combine_df(pca_df, bi)\n",
    "    X_pca, Y_pca = get_X_y(combined_pca, y)\n",
    "    X_pca.columns = X_pca.columns.astype(str)\n",
    "    training(X_pca, Y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f0a63-a7ed-4c73-98e3-0624bd8c7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 3\n",
    "# PCA Dim = 128\n",
    "get_result(metab1_path, metab3_path, 3, 128, host_age_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fe949-1a66-42bb-a752-eeb1550fc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 10\n",
    "# PCA Dim = 256\n",
    "get_result(metab1_path, metab3_path, 10, 256, host_age_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeffe8-fe48-49d4-b22b-907107dfe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 1:\n",
    "# RPCA Dim = 16\n",
    "# PCA Dim = 512\n",
    "get_result(metab1_path, metab3_path, 16, 512, host_age_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93e863-feff-4b42-afd7-43065cf2ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 3\n",
    "# PCA Dim = 128\n",
    "get_result(metab2_path, metab4_path, 3, 128, host_age_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6c37-c3ee-447f-b6e3-30eb59eb061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 10\n",
    "# PCA Dim = 256\n",
    "get_result(metab2_path, metab4_path, 10, 256, host_age_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff932dd-b4da-49cf-bda4-b11f3ddd115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 2:\n",
    "# RPCA Dim = 16\n",
    "# PCA Dim = 512\n",
    "get_result(metab2_path, metab4_path, 16, 512, host_age_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a696aa7-3652-4710-92cf-70116d01d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 1: RPCA Dim = 128\n",
    "get_result(metab1_path, metab3_path, 128, 1, host_age_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5fd2b-96bb-4510-8917-1ba7bb360fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 2: RPCA Dim = 128\n",
    "get_result(metab2_path, metab4_path, 128, 1, host_age_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95067837-f80d-4f90-a627-d6c432205fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47f2616-6dc7-455d-aad3-88bac044d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biom\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from biom import Table\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from skbio.stats.ordination import pcoa\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b85fd4-d8db-4b43-bfe1-26e23a2d4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f874e247-64c9-4e1c-9fe1-85451bbb0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = \"./redbiom_adrc_wolr2_fecal_v2.biom\"\n",
    "meta_path = \"./redbiom_adrc_wolr2_fecal_v2.tsv\"\n",
    "\n",
    "table = biom.load_table(table_path)\n",
    "\n",
    "meta = pd.read_csv(meta_path, sep='\\t')\n",
    "\n",
    "# print(meta.shape)\n",
    "# print(meta.head(5))\n",
    "# print(f\"Table shape: {table.shape}\")\n",
    "# print(table.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3250c2f4-4c0e-45ec-944d-4e809cc33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BIOM table to a pandas DataFrame (OTUs as rows, samples as columns)\n",
    "biom_df = pd.DataFrame(table.matrix_data.toarray(), index=table.ids(axis='observation'), columns=table.ids(axis='sample'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a179e07-837b-4ddd-87ce-f4f561813a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of binary features: 1568\n",
      "Number of numerical features: 13795\n"
     ]
    }
   ],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "\n",
    "binary_features = binary_features.drop(columns=['feature_type'])\n",
    "numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "\n",
    "print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9361d947-cce6-408b-8c13-9fd008aa1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Check general information about the table\n",
    "# print(\"Table dimensions (rows, columns):\", biom_df.shape)\n",
    "# print(\"Maximum value in the table:\", biom_df.values.max())\n",
    "# print(\"Minimum value in the table:\", biom_df.values.min())\n",
    "# print(\"Mean value in the table:\", biom_df.values.mean())\n",
    "# print(\"Standard deviation in the table:\", biom_df.values.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078b0409-e12c-4644-ae1b-d87b1773bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = numerical_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86556f20-b2cf-4160-adb9-c6e2c8a56dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = scaler.fit_transform(num_data)\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled.shape) # (13795, 13436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff4cbab-d3f3-4c7e-851f-ce94fd9a1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = MinMaxScaler()\n",
    "scaled_2 = scaler_2.fit_transform(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eded7618-20f9-405b-befe-1a148b8d9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "scaled_1 = scaler_1.fit_transform(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a7c378-1624-4791-86ae-ad47bc1920dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13436, 13795)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d28764-96bd-4a85-af19-0bdf7a4da26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = scaled[~np.isnan(scaled).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61616330-c69c-44be-bb71-8011a465b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13436, 13795)\n",
      "(13436, 13795)\n"
     ]
    }
   ],
   "source": [
    "print(scaled.shape)\n",
    "print(clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab122b13-b1cc-433e-9d06-7d15636e02ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727712897.6928103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/skbio/stats/ordination/_principal_coordinate_analysis.py:146: RuntimeWarning: The result contains negative eigenvalues. Please compare their magnitude with the magnitude of some of the largest positive eigenvalues. If the negative ones are smaller, it's probably safe to ignore them, but if they are large in magnitude, the results won't be useful. See the Notes section for more details. The smallest eigenvalue is -0.2999125480552377 and the largest is 4059092728681242.5.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PC1            PC2            PC3            PC4  \\\n",
      "0     -3.248695e+06 -576371.445652 -607291.079868  511376.074966   \n",
      "1     -3.115778e+02   39123.159677   60486.508880  -70207.490780   \n",
      "2      1.436833e+05  -48037.821287   13673.230721   -1633.312265   \n",
      "3      1.127946e+05   76440.615929   -6093.942982  -16852.402048   \n",
      "4      1.707834e+05  157426.647613  -92674.275936   50247.424616   \n",
      "...             ...            ...            ...            ...   \n",
      "13431 -3.791729e+05  -91210.138215 -123400.219649  180843.622730   \n",
      "13432 -2.704470e+05  -54108.470951 -126675.877762   83746.482084   \n",
      "13433 -7.597396e+05   89641.608099   35056.912698  -53501.198762   \n",
      "13434 -9.806089e+05 -119857.658340 -247686.524320  184542.014154   \n",
      "13435 -7.683849e+05  100479.157638  -92696.145454  -36011.426261   \n",
      "\n",
      "                 PC5           PC6           PC7            PC8  \\\n",
      "0      -74201.107154  2.679797e+05  3.506847e+05  234849.169595   \n",
      "1      -93666.208706  2.378098e+05 -2.841562e+04  143402.706447   \n",
      "2       33036.403649  6.065791e+03 -1.224040e+04   15910.551899   \n",
      "3      -14179.816407  2.575212e+04  1.001273e+05    1477.752027   \n",
      "4       20397.694347 -5.165363e+04  2.008918e+04    5846.729137   \n",
      "...              ...           ...           ...            ...   \n",
      "13431  -15362.300776  3.149308e+05  8.578648e+04   79364.588483   \n",
      "13432  -26399.510437  4.315308e+05 -3.516223e+04 -222456.517735   \n",
      "13433 -220797.620756  6.917789e+05  6.351132e+05 -233880.133093   \n",
      "13434 -118220.917252  6.415248e+05  5.019981e+05  168119.520355   \n",
      "13435 -146289.480806  1.311389e+06  1.077179e+06  315576.022418   \n",
      "\n",
      "                 PC9           PC10  ...         PC247         PC248  \\\n",
      "0      261649.676916  -40661.700213  ... -21191.545702  22539.486335   \n",
      "1       14945.535240  -44630.802604  ...   7022.123979   6787.392828   \n",
      "2      -31188.842041   31687.140760  ...   4455.727247   1273.340413   \n",
      "3      -22020.564971   18597.876495  ...   -121.929846   -247.768071   \n",
      "4        -350.495697   -4525.720935  ...   -673.954802     53.039993   \n",
      "...              ...            ...  ...           ...           ...   \n",
      "13431  -34056.090601   20459.663234  ...  10143.023332   2113.681396   \n",
      "13432  215774.185721  215009.532753  ... -12328.299653   -486.500285   \n",
      "13433  144499.028131  355051.181549  ... -14499.019033   7081.723836   \n",
      "13434 -129260.974899  -15619.511482  ...  -3058.768007  -1996.648005   \n",
      "13435   10163.986826 -156937.570532  ... -83437.231011  58860.310308   \n",
      "\n",
      "              PC249         PC250         PC251          PC252          PC253  \\\n",
      "0     -10589.707048   4376.396032  11163.026515   20920.621526   53703.747303   \n",
      "1      -5237.731472   5846.965737   1420.188191   -2133.253658    3236.159806   \n",
      "2       4869.088030  -6476.302568  -5789.211002   -2046.503232   -1709.403701   \n",
      "3        879.235595   -342.678016   3138.362204    1664.230314    -355.929777   \n",
      "4       -908.022417  -1505.184787    163.442838    -982.218407     827.932535   \n",
      "...             ...           ...           ...            ...            ...   \n",
      "13431   5414.847000   5587.694460   6431.155657   -8200.818065   -1709.627529   \n",
      "13432 -13919.905957  32932.454784 -38679.749058    4041.460402   17465.012739   \n",
      "13433   2914.689300  14751.442569  -7793.900084   -7072.019018  -11121.040726   \n",
      "13434  -2738.622444  13353.821403  -2407.987040    3533.800374  -17490.341813   \n",
      "13435  84160.853399  45841.755592 -10997.469338  121286.073763  113109.038466   \n",
      "\n",
      "               PC254         PC255         PC256  \n",
      "0      -39669.507751  36834.440877  -3980.338366  \n",
      "1        7809.404541  -2494.455133  -5385.707087  \n",
      "2        5861.806055  -1025.243144   2534.965055  \n",
      "3        -356.304136  -1380.601979  -4389.572379  \n",
      "4         674.838813    402.400113  -1232.194796  \n",
      "...              ...           ...           ...  \n",
      "13431   -1310.576215  -3807.186319   4716.409605  \n",
      "13432   22036.990954   2421.816559 -14624.543404  \n",
      "13433    -786.970303  -8762.860513  13836.940218  \n",
      "13434    -907.162471   -948.046026    974.733292  \n",
      "13435 -119984.014372 -19736.015273 -73504.177280  \n",
      "\n",
      "[13436 rows x 256 columns]\n",
      "Ordination results:\n",
      "\tMethod: Principal Coordinate Analysis (PCoA)\n",
      "\tEigvals: 13436\n",
      "\tProportion explained: 13436\n",
      "\tFeatures: N/A\n",
      "\tSamples: 13436x13436\n",
      "\tBiplot Scores: N/A\n",
      "\tSample constraints: N/A\n",
      "\tFeature IDs: N/A\n",
      "\tSample IDs: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', ...\n",
      "Execution time: 126.1169273853302 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNote: runtime has no connection with output dimension. Dim only affects how many rows we want from the result.\\nDim = 16, Execution time: 149.83883666992188 seconds\\nDim = 64, Execution time: 226.11388063430786 seconds\\nDim = 128, Execution time: 147.53481197357178 seconds\\nDim = 128, Execution time: 150.34863781929016 seconds\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled)\n",
    "\n",
    "dm = pairwise_distances(num_data, metric='euclidean')\n",
    "# dm = pairwise_distances(scaled_2, metric='euclidean')\n",
    "# dm = (dm + dm.T) / 2\n",
    "\n",
    "# dm = pairwise_distances(scaled_2, metric='euclidean')\n",
    "\n",
    "\n",
    "dim = 256\n",
    "\n",
    "pcoa_results = pcoa(dm)\n",
    "reduced = pcoa_results.samples.iloc[:, :dim]\n",
    "print(reduced)\n",
    "\n",
    "\n",
    "# View the PCoA results\n",
    "print(pcoa_results)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "'''\n",
    "Note: runtime has no connection with output dimension. Dim only affects how many rows we want from the result.\n",
    "Dim = 16, Execution time: 149.83883666992188 seconds\n",
    "Dim = 64, Execution time: 226.11388063430786 seconds\n",
    "Dim = 128, Execution time: 147.53481197357178 seconds\n",
    "Dim = 128, Execution time: 150.34863781929016 seconds\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3571ea0a-0d35-4570-b85e-384853c1a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1        0.325234\n",
      "PC2        0.085104\n",
      "PC3        0.077676\n",
      "PC4        0.068997\n",
      "PC5        0.044542\n",
      "             ...   \n",
      "PC13432    0.000000\n",
      "PC13433    0.000000\n",
      "PC13434    0.000000\n",
      "PC13435    0.000000\n",
      "PC13436    0.000000\n",
      "Length: 13436, dtype: float64\n",
      "0.9999999999999999\n",
      "PC1     0.325234\n",
      "PC2     0.085104\n",
      "PC3     0.077676\n",
      "PC4     0.068997\n",
      "PC5     0.044542\n",
      "PC6     0.033578\n",
      "PC7     0.024592\n",
      "PC8     0.016536\n",
      "PC9     0.015819\n",
      "PC10    0.015359\n",
      "PC11    0.013926\n",
      "PC12    0.012939\n",
      "PC13    0.009901\n",
      "PC14    0.009748\n",
      "PC15    0.009349\n",
      "PC16    0.009036\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "explained_variance_1 = pcoa_results.eigvals / pcoa_results.eigvals.sum()\n",
    "\n",
    "cumulative_explained_variance_1 = explained_variance_1.sum()\n",
    "print(explained_variance_1)\n",
    "print(cumulative_explained_variance_1)\n",
    "print(explained_variance_1.head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c056ddb-d192-4ad3-bfc7-f02cb2aeb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skbio.stats.distance import mantel\n",
    "\n",
    "# reduced_distances = pairwise_distances(reduced, metric='euclidean')\n",
    "# original_distances = pairwise_distances(num_data, metric='euclidean')\n",
    "# correlation, p_value, _ = mantel(original_distances, reduced_distances)\n",
    "# print(f\"Mantel test correlation: {correlation}, p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d1f1a1-8f6d-4e8b-b684-b4eb2685cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(scaled)\n",
    "\n",
    "# # dm = pairwise_distances(num_data, metric='euclidean')\n",
    "# # dm = pairwise_distances(scaled_1, metric='euclidean')\n",
    "# # dm = (dm + dm.T) / 2\n",
    "\n",
    "# dm = pairwise_distances(scaled_2, metric='euclidean')\n",
    "\n",
    "\n",
    "# dim = 16\n",
    "\n",
    "# pcoa_results = pcoa(dm)\n",
    "# reduced = pcoa_results.samples.iloc[:, :dim]\n",
    "# print(reduced)\n",
    "\n",
    "\n",
    "# # View the PCoA results\n",
    "# print(pcoa_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c18783d-93bd-44df-b0c5-c36d3b30379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1, df2):\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return pd.concat([df1, df2], axis=1)\n",
    "    \n",
    "def get_X_y(reduced, y, cat):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna()\n",
    "    X = cleaned_df.drop(columns=[cat])\n",
    "    y = cleaned_df[cat]\n",
    "    return X, y\n",
    "\n",
    "def training(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # # MLP\n",
    "    # mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=5000, random_state=42)\n",
    "    # mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    # y_pred_mlp = mlp_model.predict(X_test)\n",
    "    # mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    # print(f\"MLP Regressor MSE: {mse_mlp}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfaec82b-1d8d-4fd2-a984-dab901ab3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = 'host_age'\n",
    "# cat_y = meta[cat]\n",
    "# cat_X = combine_df(reduced, binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f7de46-968f-4c73-8a33-06f4a1a1bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = get_X_y(cat_X, cat_y, cat)\n",
    "# training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716a4e03-160c-47ce-857b-fce8e8acee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13436, 1825)\n",
      "(13436, 1825)\n",
      "Linear Regression MSE: 247037.21177537154\n",
      "Random Forest MSE: 215.7651744320405\n",
      "XGBoost MSE: 204.33327737775818\n"
     ]
    }
   ],
   "source": [
    "cat = 'host_age'\n",
    "\n",
    "reduced_df = combine_df(reduced, binary_features.T)\n",
    "reduced_df.index = num_data.index\n",
    "reduced_df.index.name = '#SampleID'\n",
    "meta_df = meta.set_index('#SampleID')\n",
    "\n",
    "merged_df = pd.merge(reduced_df, meta_df[cat], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "f_cleaned_df = merged_df.dropna()\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "print(cleaned_df.shape)\n",
    "print(f_cleaned_df.shape)\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']\n",
    "training(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "059bd592-ffc2-4b3f-999a-68425951460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f488b7-5606-4309-b7b4-68738dc386dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCoA, Dim = 16\n",
    "\n",
    "# # Linear Regression MSE: 80720753047910.94\n",
    "# # Random Forest MSE: 290.40436212971275\n",
    "# # XGBoost MSE: 300.0148567682974\n",
    "\n",
    "# # PC1     0.325234\n",
    "# # PC2     0.085104\n",
    "# # PC3     0.077676\n",
    "# # PC4     0.068997\n",
    "# # PC5     0.044542\n",
    "# # PC6     0.033578\n",
    "# # PC7     0.024592\n",
    "# # PC8     0.016536\n",
    "# # PC9     0.015819\n",
    "# # PC10    0.015359\n",
    "# # PC11    0.013926\n",
    "# # PC12    0.012939\n",
    "# # PC13    0.009901\n",
    "# # PC14    0.009748\n",
    "# # PC15    0.009349\n",
    "# # PC16    0.009036\n",
    "# # dtype: float64\n",
    "\n",
    "# dim = 128\n",
    "# (13436, 1697)\n",
    "# (13436, 1697)\n",
    "# Linear Regression MSE: 51820.4883765476\n",
    "# Random Forest MSE: 218.34668141373584\n",
    "# XGBoost MSE: 211.44149421183153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11b5bf-3f6d-4d3e-a9db-3a327dad28c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727329770.3884413\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde79c9c-af59-4250-84a5-0b1766e242d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1, df2):\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return pd.concat([df1, df2], axis=1)\n",
    "    \n",
    "def get_X_y(reduced, y, cat):\n",
    "    combined_df = combine_df(reduced, y)\n",
    "    cleaned_df = combined_df.dropna()\n",
    "    X = cleaned_df.drop(columns=[cat])\n",
    "    y = cleaned_df[cat]\n",
    "    return X, y\n",
    "\n",
    "def training(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "\n",
    "    # # MLP\n",
    "    # mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=5000, random_state=42)\n",
    "    # mlp_model.fit(X_train, y_train)\n",
    "    \n",
    "    # y_pred_mlp = mlp_model.predict(X_test)\n",
    "    # mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "    # print(f\"MLP Regressor MSE: {mse_mlp}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8df780-5ec3-4231-938a-7c88524391be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'host_age'\n",
    "cat_y = meta[y_category]\n",
    "cat_X = combine_df(reduced_data, binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c99d1-db7f-4408-bf17-99a49acaf95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(cat_X, cat_y, cat)\n",
    "training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668ea23-b4ab-46b9-a46c-ffd38e5aadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dim = 3\n",
    "# Linear Regression MSE: 3.995264211009359e+28\n",
    "# Random Forest MSE: 332.3066680347287\n",
    "# /opt/conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
    "#   warnings.warn(\"Training interrupted by user.\")\n",
    "# MLP Regressor MSE: 685.7311446346571\n",
    "# XGBoost MSE: 299.14464191813653\n",
    "\n",
    "# Dim = 16\n",
    "# Reconstruction MSE: 0.00022048968863458537\n",
    "# Sample scores shape: (13436, 16)\n",
    "# Feature scores shape: (13795, 16)\n",
    "# Original scaled data shape: (13436, 13795)\n",
    "# Reconstructed data shape: (13436, 13795)\n",
    "\n",
    "# Linear Regression MSE: 1.1185584052698574e+29\n",
    "# Random Forest MSE: 297.4191591508802\n",
    "# XGBoost MSE: 306.4656906982071\n",
    "\n",
    "print(y.max())\n",
    "print(y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9e768-2e1c-496a-9c9e-5eda92437a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = numerical_features.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "scaled = pd.DataFrame(scaler.fit_transform(numerical_features.T).T, index=numerical_features.index, columns=numerical_features.columns)\n",
    "\n",
    "# print(\"Scaled Numerical Dataset:\")\n",
    "# print(scaled.head())\n",
    "# print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ea9de-eee2-46e2-8522-0aecb950e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feature(row):\n",
    "    unique_values = row.unique()\n",
    "    if len(unique_values) == 2 and set(unique_values).issubset({0, 1}):\n",
    "        return 'binary'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "def split_feature(biom_df):\n",
    "    biom_df['feature_type'] = biom_df.apply(classify_feature, axis=1)\n",
    "\n",
    "    binary_features = biom_df[biom_df['feature_type'] == 'binary']\n",
    "    numerical_features = biom_df[biom_df['feature_type'] == 'numerical']\n",
    "    \n",
    "    binary_features = binary_features.drop(columns=['feature_type'])\n",
    "    numerical_features = numerical_features.drop(columns=['feature_type'])\n",
    "    \n",
    "    print(f\"Number of binary features: {binary_features.shape[0]}\")\n",
    "    print(f\"Number of numerical features: {numerical_features.shape[0]}\")\n",
    "\n",
    "    return binary_features, numerical_features\n",
    "\n",
    "def scale_data(numerical_features):\n",
    "    scaled_d = numerical_features.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_d[numerical_features.columns] = scaler.fit_transform(numerical_features)\n",
    "    scaled = scaler.fit_transform(numerical_features.T).T\n",
    "    return scaled\n",
    "\n",
    "def rpca_fr(scaled, numerical_features, dim):\n",
    "    scaled += 1e-10\n",
    "    sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "    feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "    table_scaled = Table(scaled, feature_ids, sample_ids)\n",
    "\n",
    "    rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "    ordination, distance = rpca_results\n",
    "    sample_scores = ordination.samples  # Scores for samples\n",
    "    feature_scores = ordination.features  # Scores for features\n",
    "    \n",
    "    X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "    \n",
    "    mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "    print(f\"Reconstruction MSE: {mse}\")\n",
    "    \n",
    "    print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "    print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "    print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "    print(f\"Reconstructed data shape: {X_reconstructed.shape}\")\n",
    "\n",
    "    return sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787d6e0-f73a-48d8-b09b-97f25d393b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca(df, dim):\n",
    "    bin_data, num_data = split_feature(df)\n",
    "    scaled_data = scale_data(num_data)\n",
    "    reduced_data = rpca_fr(scaled_data, num_data, dim)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e87dca-d012-4160-bf20-4496d9b828ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpca(biom_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadded7-32e8-477e-87c1-30b8afdf82f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d470e-ff1e-43ae-9df4-409bd005176a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d8688-0ad3-41fb-8d7b-5cf7bd04a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += 1e-10\n",
    "sample_ids = numerical_features.columns.tolist()  # Sample IDs (columns)\n",
    "feature_ids = numerical_features.index.tolist()   # Feature IDs (rows)\n",
    "table_scaled = Table(scaled, feature_ids, sample_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5008b3f-1a82-499c-897f-5c8726ff1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3  # Number of components to reduce to\n",
    "rpca_results = rpca(table_scaled, n_components=dim)\n",
    "\n",
    "ordination, distance = rpca_results\n",
    "sample_scores = ordination.samples  # Scores for samples\n",
    "feature_scores = ordination.features  # Scores for features\n",
    "\n",
    "X_reconstructed = np.dot(sample_scores, feature_scores.T)\n",
    "\n",
    "mse = mean_squared_error(scaled.T, X_reconstructed)\n",
    "print(f\"Reconstruction MSE: {mse}\")\n",
    "\n",
    "print(f\"Sample scores shape: {sample_scores.shape}\")\n",
    "print(f\"Feature scores shape: {feature_scores.shape}\")\n",
    "print(f\"Original scaled data shape: {scaled.T.shape}\")\n",
    "print(f\"Reconstructed data shape: {X_reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81136b2e-6364-43c8-a7df-35f846aed677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction MSE: 0.003958728646643008\n",
    "# Sample scores shape: (1312, 3)\n",
    "# Feature scores shape: (1102, 3)\n",
    "# Original scaled data shape: (1312, 1102)\n",
    "# Reconstructed data shape: (1312, 1102)\n",
    "\n",
    "\n",
    "# Reconstruction MSE: 0.0033221211643852722\n",
    "# Sample scores shape: (1312, 10)\n",
    "# Feature scores shape: (8448, 10)\n",
    "# Original scaled data shape: (1312, 8448)\n",
    "# Reconstructed data shape: (1312, 8448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafb11d-9636-4cad-873c-8ba30e505315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordination)\n",
    "print(distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752e67b-ff23-40b1-9fa8-62f8a772c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using reduced scaled numerical dataset\n",
    "reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b440b0b-3220-46de-a482-d523b1aaf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using both binary and reduced numerical dataset\n",
    "# reduced_df = pd.DataFrame(sample_scores, index=sample_ids)\n",
    "\n",
    "# binary_transposed = binary_features.T \n",
    "# # reduced_df.index = reduced_df.index.astype(float)\n",
    "# # print(reduced_df.index)\n",
    "# # print(binary_transposed.index)\n",
    "# # print(\"Do sample names match?\", (reduced_df.index == binary_transposed.index).all())\n",
    "# combined_df = pd.concat([reduced_df, binary_transposed], axis=1)\n",
    "# combined_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "# meta_df = meta.set_index('sample_name')\n",
    "\n",
    "# merged_df = combined_df.join(metadata_df[['host_age']], how='inner')\n",
    "# cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# # print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# # print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# # # Original dataset shape: (1312, 1749)\n",
    "# # # Cleaned dataset shape: (1301, 1749)\n",
    "\n",
    "# X = cleaned_df.drop(columns=['host_age'])\n",
    "# Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca04a73-b8b8-4341-8fc0-24202551e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b456ac-8a26-4758-9630-5771d95ad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a56e40-9e53-4884-91da-daccc97c87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5167e-1752-4aa4-b239-474421634e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94412bce-5232-4b50-9506-fc81cd05d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------RPCA Num ONLY--------\n",
    "Dim = 3\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003958728646643008\n",
    "Cleaned dataset shape: (1301, 4)\n",
    "Linear Regression MSE: 68.19986181183467\n",
    "Random Forest MSE: 75.95139961685823\n",
    "MLP Regressor MSE: 68.22414791217268\n",
    "XGBoost MSE: 76.82236484129864\n",
    "\n",
    "Dim = 10\n",
    "Scaler: MinMax Scaler\n",
    "Reconstruction MSE: 0.003946154448124425\n",
    "Linear Regression MSE: 59.808153281084984\n",
    "Random Forest MSE: 62.939483908045986\n",
    "MLP Regressor MSE: 59.78929765458566\n",
    "XGBoost MSE: 64.94144790232647\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5d3eb-16ff-40c8-b434-e6b6359106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_transposed = numerical_features.T\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data_transposed)\n",
    "\n",
    "reduced_dim = 512\n",
    "pca = PCA(n_components=reduced_dim, svd_solver='auto')\n",
    "pca_reduced = pca.fit_transform(standardized_data)\n",
    "pca_reconstructed = pca.inverse_transform(pca_reduced)\n",
    "\n",
    "mse_pca = mean_squared_error(standardized_data, pca_reconstructed)\n",
    "\n",
    "print(mse_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7905-19dc-4d61-960a-6a2f9e11c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.DataFrame(pca_reduced, index=sample_ids)\n",
    "reduced_df.index = reduced_df.index.astype(float)\n",
    "\n",
    "meta_df = meta.set_index('sample_name')\n",
    "\n",
    "merged_df = reduced_df.join(metadata_df[['host_age']], how='inner')\n",
    "\n",
    "# print(merged_df.head())\n",
    "# print(merged_df.shape)\n",
    "\n",
    "cleaned_df = merged_df.dropna(subset=['host_age'])\n",
    "\n",
    "# print(f\"Original dataset shape: {merged_df.shape}\")\n",
    "# print(f\"Cleaned dataset shape: {cleaned_df.shape}\")\n",
    "# Original dataset shape: (1312, 4)\n",
    "# Cleaned dataset shape: (1301, 4)\n",
    "\n",
    "X = cleaned_df.drop(columns=['host_age'])\n",
    "Y = cleaned_df['host_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d15b9d-2d84-49e0-b886-e00517a9d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train\n",
    "\n",
    "# Initialize and fit the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eeaee6-6905-4886-b637-e6cf45dde8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93ad2a-89d5-4fe6-9cc6-0427c5b0d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Regressor MSE: {mse_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba6f61-48e8-4256-91d0-5c2200489221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9307088-2a94-4aa0-9c4c-d1b5096176af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------PCA--------\n",
    "Dim = 128\n",
    "Reconstruction MSE(full): 0.32280275488908244\n",
    "Cleaned dataset shape: (1301, 129)\n",
    "Linear Regression MSE: 2841.559584303109\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 895.1086733724248\n",
    "XGBoost MSE: 70.36381670902817\n",
    "\n",
    "Reconstruction MSE(auto): 0.32696752866827633\n",
    "Linear Regression MSE: 97.59366339211996\n",
    "Random Forest MSE: 64.57761494252874\n",
    "MLP Regressor MSE: 970.4559274788406\n",
    "XGBoost MSE: 64.4298729789169\n",
    "\n",
    "Dim = 512\n",
    "Reconstruction MSE(full): 0.01719558259971444\n",
    "Linear Regression MSE: 551.90068430994\n",
    "Random Forest MSE: 66.89663639846744\n",
    "MLP Regressor MSE: 811.2290273839908\n",
    "XGBoost MSE: 69.61207270397696\n",
    "\n",
    "Reconstruction MSE(auto): 0.01743150302309283\n",
    "Linear Regression MSE: 580.8346541828049\n",
    "Random Forest MSE: 63.36988850574713\n",
    "MLP Regressor MSE: 911.1563581922785\n",
    "XGBoost MSE: 67.18452645782199\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eadbfa-c3b0-42bd-a315-27fd95d30794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_df['host_age'].max())\n",
    "print(cleaned_df['host_age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59cc7c-4c26-49e6-9f0f-cbaebc9641de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
